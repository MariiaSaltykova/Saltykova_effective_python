{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariiaSaltykova/Saltykova_effective_python/blob/master/12_gnn_mpnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neural Networks (GNNs)\n",
        "## Part I: Message Passing Neural Networks (MPNNs)\n",
        "We are going to implement few MPNNs for molecular property prediciton. It's recommended that you're familiar with the recent lectures on GNNs."
      ],
      "metadata": {
        "collapsed": false,
        "id": "9bec6577a3d2a155"
      },
      "id": "9bec6577a3d2a155"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages for GNNs\n",
        "There two very popular packages for GNNs that uses pytorch as a backend:\n",
        "1. [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html).\n",
        "2. [Deep Graph Library](https://www.dgl.ai/pages/start.html) (along with [dgl-lifesci](https://lifesci.dgl.ai/install/index.html).\n",
        "The former is more stable, the latter has a convenient extension [dgl-lifesci](https://lifesci.dgl.ai/generated/dgllife.utils.CanonicalAtomFeaturizer.html) for molecular data and is generally much more user-friendly. For convenience, we are going to use all three packages, so install appropriate versions of them, please (I recommend installing with pip). If you have issues with installing rdkit (required by dgl-lifesci), you can install rdkit using pip (pip install rdkit).\n",
        "\n",
        "Some additional packages that we are going to use:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "a10f517285d85363"
      },
      "id": "a10f517285d85363"
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.39.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics # or conda install -c conda-forge torchmetrics\n",
        "!pip install wandb # or conda install -c conda-forge wandb"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:37:57.343999Z",
          "start_time": "2023-12-11T15:37:57.341666Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dec783bf177280f0",
        "outputId": "4bc1561b-ad10-470a-f579-a059df03266b"
      },
      "id": "dec783bf177280f0"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgllife # or conda install -c conda-forge torchmetrics\n",
        "!pip install dgl # or conda install -c conda-forge wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zk1wN8cFqfT",
        "outputId": "68ebef02-ee21-4b61-c646-32184030e716"
      },
      "id": "5zk1wN8cFqfT",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgllife in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgllife) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgllife) (3.2.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from dgllife) (0.2.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.16.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2023.3.post1)\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xxBGORrGDk4",
        "outputId": "d242b651-47d7-4905-d059-100840c7f64f"
      },
      "id": "5xxBGORrGDk4",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Molecular graphs\n",
        "(Copied from [mldd23 repository](https://github.com/gmum/mldd23/blob/main/labs/L3-graph-neural-networks/laboratory.ipynb))\n",
        "In mathematics, a graph is an object that consists of a set of vertices (nodes) connected with edges, i.e. $\\mathcal{G} = (V, E)$, where $V = \\{ v_i: i \\in \\{1, 2, \\dots, N \\} \\}$ and $E \\subseteq \\{ (v_i, v_j):\\, v_i,v_j \\in V \\}$.\n",
        "\n",
        "Molecular graphs are a special class of graphs, where besides nodes (denoting atoms) and edges (denoting chemical bonds), we have an additional information about atom types and sometimes also bond types. We can assume that we have an additional set of node/atom features encoded as a matrix $X$, where $X_{ij}$ is the $j$-th feature of the $i$-th atom. As atomic features, we can have one-hot encoded atom symbols (a vector containing zeros on all positions besides the position that corresponds to the atom symbol), the number of implicit hydrogens bonded with this atom, or the number of heavy neighbors (atoms other than hydrogens bonded to the given atom).\n",
        "\n",
        "Egdes/bonds can be encoded in two different ways. One method is to use an adjacency matrix $A$, where $A_{ij}=1$ if nodes/atoms $v_i$ nad $v_j$ are connected ($A_{ij}=0$ otherwise). In the case of sparse matrices, a more useful encoding is a list of pairs of connected atoms (a list of index pairs). This latter enocding is used by the PyTorch-Geometric library.\n",
        "\n",
        "In practice, a molecular graph can be described by two matrices: $X \\in \\mathbb{R}^{N \\times F}$ and $E \\in \\{0, 1,\\dots,N-1\\}^{2 \\times N}$, where $N$ is the number of atoms, and $F$ is the number of atomic features.\n",
        "<img src=\"https://github.com/MariiaSaltykova/machine_learning/blob/main/resources/mol_graph.png?raw=1\" height=\"500\" />"
      ],
      "metadata": {
        "collapsed": false,
        "id": "61eff200e2fa43b4"
      },
      "id": "61eff200e2fa43b4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "7533978cf98913d"
      },
      "id": "7533978cf98913d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to use FreeSolv dataset that contains 642 hydration free energy values for small molecules. The goal is to predict the [hydration free energy](https://en.wikipedia.org/wiki/Hydration_energy) of a given molecule. It's a very commonly used dataset for benchmarking molecular property prediction models. It's small, so we can minimize our co2 footprint and time spent on training.\n",
        "\n",
        "Molecules in most chemical datasets are represented with SMILES. SMILES is a linearization of the molecular graph, it's pretty convenient and can even be used as an input to text-based models. Fortunately, dgllife provides a fancy FreeSolv dataset wrapper that will 1) transform the SMILES into a molecular graph, and 2) encode the nodes and edges with some sensible chemical features (like atom types, bond type etc.) with node and edge features, so we don't really need to care about it."
      ],
      "metadata": {
        "collapsed": false,
        "id": "f7eeba76a4a89736"
      },
      "id": "f7eeba76a4a89736"
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing dgl graphs from scratch...\n"
          ]
        }
      ],
      "source": [
        "from dgllife.utils import CanonicalAtomFeaturizer, CanonicalBondFeaturizer, SMILESToBigraph\n",
        "from dgllife.data import FreeSolv\n",
        "import torch\n",
        "import dgl\n",
        "\n",
        "node_featurizer = CanonicalAtomFeaturizer()\n",
        "edge_featurizer = CanonicalBondFeaturizer(self_loop=True)\n",
        "dataset = FreeSolv(\n",
        "    smiles_to_graph=SMILESToBigraph(\n",
        "        node_featurizer=node_featurizer,\n",
        "        edge_featurizer=edge_featurizer,\n",
        "        add_self_loop=True,\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.562914Z",
          "start_time": "2023-12-11T15:15:48.616258Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6b97de5d9371cf2",
        "outputId": "01b7b6bb-d470-4b8d-fda4-06c518104e4b"
      },
      "id": "e6b97de5d9371cf2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Playground"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9bf700b3346f6a31"
      },
      "id": "9bf700b3346f6a31"
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('CN(C)C(=O)c1ccc(cc1)OC',\n",
              " Graph(num_nodes=13, num_edges=39,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
              " tensor([-11.0100]))"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ],
      "source": [
        "smiles, graph, label = dataset[0]\n",
        "smiles, graph, label"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.568451Z",
          "start_time": "2023-12-11T15:15:49.564290Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd08f424238c9580",
        "outputId": "47e20e2f-d7a7-4da6-c9d6-f9307964c1a3"
      },
      "id": "fd08f424238c9580"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the dataset item consist of a SMILES string, a graph, and a label. The graph is a [DGLGraph](https://docs.dgl.ai/en/0.8.x/api/python/dgl.DGLGraph.html) object that contains node and edge features. We can access them with the following code:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b297de83ea20e626"
      },
      "id": "b297de83ea20e626"
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 74])"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ],
      "source": [
        "graph.ndata['h'].shape  # node features"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.571379Z",
          "start_time": "2023-12-11T15:15:49.567706Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6cd6aafddd20202",
        "outputId": "f41de885-b174-458f-d0b4-e39d12f22c96"
      },
      "id": "f6cd6aafddd20202"
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([39, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ],
      "source": [
        "graph.edata['e'].shape  # edge features"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.585687Z",
          "start_time": "2023-12-11T15:15:49.571477Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "972195282cdfb48f",
        "outputId": "89790461-248b-49ed-ddf8-6b2353ba6e16"
      },
      "id": "972195282cdfb48f"
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12,  0],\n",
              "        [ 0, 12],\n",
              "        [ 0,  2],\n",
              "        [ 2,  0],\n",
              "        [ 0,  4],\n",
              "        [ 4,  0],\n",
              "        [ 4,  7],\n",
              "        [ 7,  4],\n",
              "        [ 4,  9],\n",
              "        [ 9,  4],\n",
              "        [ 9,  6],\n",
              "        [ 6,  9],\n",
              "        [ 6, 10],\n",
              "        [10,  6],\n",
              "        [10, 11],\n",
              "        [11, 10],\n",
              "        [11,  3],\n",
              "        [ 3, 11],\n",
              "        [ 3,  8],\n",
              "        [ 8,  3],\n",
              "        [11,  5],\n",
              "        [ 5, 11],\n",
              "        [ 5,  1],\n",
              "        [ 1,  5],\n",
              "        [ 8,  9],\n",
              "        [ 9,  8],\n",
              "        [ 0,  0],\n",
              "        [ 1,  1],\n",
              "        [ 2,  2],\n",
              "        [ 3,  3],\n",
              "        [ 4,  4],\n",
              "        [ 5,  5],\n",
              "        [ 6,  6],\n",
              "        [ 7,  7],\n",
              "        [ 8,  8],\n",
              "        [ 9,  9],\n",
              "        [10, 10],\n",
              "        [11, 11],\n",
              "        [12, 12]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ],
      "source": [
        "start_nodes, end_nodes = graph.edges()  # edges. Note that edges are directed, so we have two edges for each bond. Moreover, we have self-loops, to easily handle molecules with only one atom.\n",
        "edges = torch.stack([start_nodes, end_nodes], dim=1)\n",
        "edges"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.585880Z",
          "start_time": "2023-12-11T15:15:49.574913Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf1af8de0703b2d3",
        "outputId": "8e1462ea-8e27-40db-b6fe-2eafcac35bd1"
      },
      "id": "bf1af8de0703b2d3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importantly, if we want to create a batch of graphs, we can simply treat the graphs as... a single graph with many disconnected components. The reason is that MPNN cannot pass the message between disconnected compontents, so the graphs in a batch won't influence each other. To make a batch from two graphs, we can simply run:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "611ba9d29599927d"
      },
      "id": "611ba9d29599927d"
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Graph(num_nodes=13, num_edges=39,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
              " Graph(num_nodes=5, num_edges=13,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
              " Graph(num_nodes=18, num_edges=52,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}))"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ],
      "source": [
        "_, graph_1, _ = dataset[0]\n",
        "_, graph_2, _ = dataset[1]\n",
        "collated_graph = dgl.batch([graph_1, graph_2])\n",
        "graph_1, graph_2, collated_graph"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.585967Z",
          "start_time": "2023-12-11T15:15:49.578783Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1063ec4d70a6c648",
        "outputId": "7f6fed0c-79c5-49c9-9a50-a08a34949496"
      },
      "id": "1063ec4d70a6c648"
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13,  5])"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ],
      "source": [
        "collated_graph.batch_num_nodes()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.659167Z",
          "start_time": "2023-12-11T15:15:49.583356Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd9357b97e4c3b1b",
        "outputId": "df00ba59-bc6e-4a31-ab6b-39c3ef90f88d"
      },
      "id": "cd9357b97e4c3b1b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the collated_graph, the ids corresponding to the nodes of graph_2 are shifted by the size of graph_1:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b37a35a6ae91e55d"
      },
      "id": "b37a35a6ae91e55d"
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=torch.int32),\n",
              " tensor([0, 1, 2, 3, 4], dtype=torch.int32),\n",
              " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
              "        dtype=torch.int32))"
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ],
      "source": [
        "graph_1.nodes(), graph_2.nodes(), collated_graph.nodes()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.673590Z",
          "start_time": "2023-12-11T15:15:49.586749Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7598293d45c78c0",
        "outputId": "6b2dd5e6-8995-4d4c-8507-094047f60d03"
      },
      "id": "7598293d45c78c0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split\n",
        "We are going to make our split slightly harder by using [scaffold](https://hub.knime.com/infocom/extensions/jp.co.infocom.cheminfo.jchem.feature/latest/jp.co.infocom.cheminfo.jchem.bemismurckoclustering.BemisMurckoClusteringNodeFactory) (scaffold is the largest cycle in a molecule) splitting that puts molecules with similar scaffolds to the same split."
      ],
      "metadata": {
        "collapsed": false,
        "id": "e67b6515649fa77d"
      },
      "id": "e67b6515649fa77d"
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start initializing RDKit molecule instances...\n",
            "Start computing Bemis-Murcko scaffolds.\n"
          ]
        }
      ],
      "source": [
        "from dgllife.utils import ScaffoldSplitter\n",
        "\n",
        "splitter = ScaffoldSplitter()\n",
        "train, valid, test = splitter.train_val_test_split(dataset)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.674260Z",
          "start_time": "2023-12-11T15:15:49.620132Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "901db3d9cdc5a748",
        "outputId": "5715f68e-1bec-4cc7-c34c-751a9e27217e"
      },
      "id": "901db3d9cdc5a748"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ukVIEd9GmVx",
        "outputId": "65e45821-bfff-4e99-a414-00fca9827e67"
      },
      "id": "_ukVIEd9GmVx",
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: utils in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Callable, Tuple, List, Type\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import utils\n",
        "from types import SimpleNamespace\n",
        "from torch.optim import SGD\n",
        "from torch.optim import Adagrad as torch_adagrad\n",
        "from torch.optim import RMSprop as torch_rmsprop\n",
        "from torch.optim import Adadelta as torch_adadelta\n",
        "from torch.optim import Adam as torch_adam\n",
        "\n",
        "\n",
        "def check_closest(fn: Callable) -> None:\n",
        "    inputs = [\n",
        "        (6, np.array([5, 3, 4])),\n",
        "        (10, np.array([12, 2, 8, 9, 13, 14])),\n",
        "        (-2, np.array([-5, 12, 6, 0, -14, 3])),\n",
        "    ]\n",
        "    assert np.isclose(fn(*inputs[0]), 5), \"Jest błąd w funkcji closest!\"\n",
        "    assert np.isclose(fn(*inputs[1]), 9), \"Jest błąd w funkcji closest!\"\n",
        "    assert np.isclose(fn(*inputs[2]), 0), \"Jest błąd w funkcji closest!\"\n",
        "\n",
        "\n",
        "def check_poly(fn: Callable) -> None:\n",
        "    inputs = [\n",
        "        (6, np.array([5.5, 3, 4])),\n",
        "        (10, np.array([12, 2, 8, 9, 13, 14])),\n",
        "        (-5, np.array([6, 3, -12, 9, -15])),\n",
        "    ]\n",
        "    assert np.isclose(fn(*inputs[0]), 167.5), \"Jest błąd w funkcji poly!\"\n",
        "    assert np.isclose(fn(*inputs[1]), 1539832), \"Jest błąd w funkcji poly!\"\n",
        "    assert np.isclose(fn(*inputs[2]), -10809), \"Jest błąd w funkcji poly!\"\n",
        "\n",
        "\n",
        "def check_multiplication_table(fn: Callable) -> None:\n",
        "    inputs = [3, 5]\n",
        "    assert np.all(\n",
        "        fn(inputs[0]) == np.array([[1, 2, 3], [2, 4, 6], [3, 6, 9]])\n",
        "    ), \"Jest błąd w funkcji multiplication_table!\"\n",
        "    assert np.all(\n",
        "        fn(inputs[1])\n",
        "        == np.array(\n",
        "            [\n",
        "                [1, 2, 3, 4, 5],\n",
        "                [2, 4, 6, 8, 10],\n",
        "                [3, 6, 9, 12, 15],\n",
        "                [4, 8, 12, 16, 20],\n",
        "                [5, 10, 15, 20, 25],\n",
        "            ]\n",
        "        )\n",
        "    ), \"Jest błąd w funkcji multiplication_table!\"\n",
        "\n",
        "\n",
        "def check_1_1(\n",
        "        mean_error: Callable,\n",
        "        mean_squared_error: Callable,\n",
        "        max_error: Callable,\n",
        "        train_sets: List[np.ndarray],\n",
        ") -> None:\n",
        "    train_set_1d, train_set_2d, train_set_10d = train_sets\n",
        "    assert np.isclose(mean_error(train_set_1d, np.array([8])), 8.897352)\n",
        "    assert np.isclose(mean_error(train_set_2d, np.array([2.5, 5.2])), 7.89366)\n",
        "    assert np.isclose(mean_error(train_set_10d, np.array(np.arange(10))), 14.16922)\n",
        "\n",
        "    assert np.isclose(mean_squared_error(train_set_1d, np.array([3])), 23.03568)\n",
        "    assert np.isclose(mean_squared_error(train_set_2d, np.array([2.4, 8.9])), 124.9397)\n",
        "    assert np.isclose(mean_squared_error(train_set_10d, -np.arange(10)), 519.1699)\n",
        "\n",
        "    assert np.isclose(max_error(train_set_1d, np.array([3])), 7.89418)\n",
        "    assert np.isclose(max_error(train_set_2d, np.array([2.4, 8.9])), 14.8628)\n",
        "    assert np.isclose(max_error(train_set_10d, -np.linspace(0, 5, num=10)), 23.1727)\n",
        "\n",
        "\n",
        "def check_1_2(\n",
        "        minimize_me: Callable, minimize_mse: Callable, minimize_max: Callable, train_set_1d: np.ndarray\n",
        ") -> None:\n",
        "    assert np.isclose(minimize_mse(train_set_1d), -0.89735)\n",
        "    assert np.isclose(minimize_mse(train_set_1d * 2), -1.79470584)\n",
        "    assert np.isclose(minimize_me(train_set_1d), -1.62603)\n",
        "    assert np.isclose(minimize_me(train_set_1d ** 2), 3.965143)\n",
        "    assert np.isclose(minimize_max(train_set_1d), 0.0152038)\n",
        "    assert np.isclose(minimize_max(train_set_1d / 2), 0.007601903895526174)\n",
        "\n",
        "\n",
        "def check_1_3(\n",
        "        me_grad: Callable, mse_grad: Callable, max_grad: Callable, train_sets: List[np.ndarray]\n",
        ") -> None:\n",
        "    train_set_1d, train_set_2d, train_set_10d = train_sets\n",
        "    assert all(np.isclose(me_grad(train_set_1d, np.array([0.99])), [0.46666667]))\n",
        "    assert all(np.isclose(me_grad(train_set_2d, np.array([0.99, 8.44])), [0.21458924, 0.89772834]))\n",
        "    assert all(\n",
        "        np.isclose(\n",
        "            me_grad(train_set_10d, np.linspace(0, 10, num=10)),\n",
        "            [\n",
        "                -0.14131273,\n",
        "                -0.031631,\n",
        "                0.04742431,\n",
        "                0.0353542,\n",
        "                0.16364242,\n",
        "                0.23353252,\n",
        "                0.30958123,\n",
        "                0.35552034,\n",
        "                0.4747464,\n",
        "                0.55116738,\n",
        "            ],\n",
        "        )\n",
        "    )\n",
        "\n",
        "    assert all(np.isclose(mse_grad(train_set_1d, np.array([1.24])), [4.27470585]))\n",
        "    assert all(\n",
        "        np.isclose(mse_grad(train_set_2d, np.array([-8.44, 10.24])), [-14.25378235, 21.80373175])\n",
        "    )\n",
        "    assert all(np.isclose(max_grad(train_set_1d, np.array([5.25])), [1.0]))\n",
        "    assert all(\n",
        "        np.isclose(max_grad(train_set_2d, np.array([-6.28, -4.45])), [-0.77818704, -0.62803259])\n",
        "    )\n",
        "\n",
        "\n",
        "def check_02_linear_regression(lr_cls: Type) -> None:\n",
        "    from sklearn import datasets\n",
        "\n",
        "    np.random.seed(54)\n",
        "\n",
        "    input_dataset = datasets.load_diabetes()\n",
        "    lr = lr_cls()\n",
        "    lr.fit(input_dataset.data, input_dataset.target)\n",
        "    returned = lr.predict(input_dataset.data)\n",
        "    expected = np.load(\".checker/05/lr_diabetes.out.npz\")[\"data\"]\n",
        "    assert np.allclose(expected, returned, rtol=1e-03, atol=1e-06), \"Wrong prediction returned!\"\n",
        "\n",
        "    loss = lr.loss(input_dataset.data, input_dataset.target)\n",
        "    assert np.isclose(\n",
        "        loss, 26004.287402, rtol=1e-03, atol=1e-06\n",
        "    ), \"Wrong value of the loss function!\"\n",
        "\n",
        "\n",
        "def check_02_regularized_linear_regression(lr_cls: Type) -> None:\n",
        "    from sklearn import datasets\n",
        "\n",
        "    np.random.seed(54)\n",
        "\n",
        "    input_dataset = datasets.load_diabetes()\n",
        "    lr = lr_cls(lr=1e-2, alpha=1e-4)\n",
        "    lr.fit(input_dataset.data, input_dataset.target)\n",
        "    returned = lr.predict(input_dataset.data)\n",
        "    # np.savez_compressed(\".checker/05/rlr_diabetes.out.npz\", data=returned)\n",
        "    expected = np.load(\".checker/05/rlr_diabetes.out.npz\")[\"data\"]\n",
        "    assert np.allclose(expected, returned, rtol=1e-03, atol=1e-06), \"Wrong prediction returned!\"\n",
        "\n",
        "    loss = lr.loss(input_dataset.data, input_dataset.target)\n",
        "    assert np.isclose(\n",
        "        loss, 26111.08336411, rtol=1e-03, atol=1e-06\n",
        "    ), \"Wrong value of the loss function!\"\n",
        "\n",
        "\n",
        "def check_4_1_mse(fn: Callable, datasets: List[Tuple[np.ndarray, np.ndarray]]) -> None:\n",
        "    results = [torch.tensor(13.8520), torch.tensor(31.6952)]\n",
        "    for (data, param), loss in zip(datasets, results):\n",
        "        result = fn(data, param)\n",
        "        assert torch.allclose(fn(data, param), loss, atol=1e-3), \"Wrong loss returned!\"\n",
        "\n",
        "\n",
        "def check_4_1_me(fn: Callable, datasets: List[Tuple[np.ndarray, np.ndarray]]) -> None:\n",
        "    results = [torch.tensor(3.6090), torch.tensor(5.5731)]\n",
        "    for (data, param), loss in zip(datasets, results):\n",
        "        assert torch.allclose(fn(data, param), loss, atol=1e-3), \"Wrong loss returned!\"\n",
        "\n",
        "\n",
        "def check_4_1_max(fn: Callable, datasets: List[Tuple[np.ndarray, np.ndarray]]) -> None:\n",
        "    results = [torch.tensor(7.1878), torch.tensor(7.5150)]\n",
        "    for (data, param), loss in zip(datasets, results):\n",
        "        assert torch.allclose(fn(data, param), loss, atol=1e-3), \"Wrong loss returned!\"\n",
        "\n",
        "\n",
        "def check_4_1_lin_reg(fn: Callable, data: List[np.ndarray]) -> None:\n",
        "    X, y, w = data\n",
        "    assert torch.allclose(fn(X, w, y), torch.tensor(29071.6699), atol=1e-3), \"Wrong loss returned!\"\n",
        "\n",
        "\n",
        "def check_4_1_reg_reg(fn: Callable, data: List[np.ndarray]) -> None:\n",
        "    X, y, w = data\n",
        "    assert torch.allclose(fn(X, w, y), torch.tensor(29073.4551)), \"Wrong loss returned!\"\n",
        "\n",
        "\n",
        "def check_04_logistic_reg(lr_cls: Type) -> None:\n",
        "    np.random.seed(10)\n",
        "    torch.manual_seed(10)\n",
        "\n",
        "    # **** First dataset ****\n",
        "    input_dataset = utils.get_classification_dataset_1d()\n",
        "    lr = lr_cls(1)\n",
        "    lr.fit(input_dataset.data, input_dataset.target, lr=1e-3, num_steps=int(1e4))\n",
        "    returned = lr.predict(input_dataset.data)\n",
        "    save_path = \".checker/04/lr_dataset_1d.out.torch\"\n",
        "    # torch.save(returned, save_path)\n",
        "    expected = torch.load(save_path)\n",
        "    assert torch.allclose(expected, returned, rtol=1e-03, atol=1e-06), \"Wrong prediction returned!\"\n",
        "\n",
        "    returned = lr.predict_proba(input_dataset.data)\n",
        "    save_path = \".checker/04/lr_dataset_1d_proba.out.torch\"\n",
        "    # torch.save(returned, save_path)\n",
        "    expected = torch.load(save_path)\n",
        "    assert torch.allclose(expected, returned, rtol=1e-03, atol=1e-06), \"Wrong prediction returned!\"\n",
        "\n",
        "    returned = lr.predict(input_dataset.data)\n",
        "    save_path = \".checker/04/lr_dataset_1d_preds.out.torch\"\n",
        "    # torch.save(returned, save_path)\n",
        "    expected = torch.load(save_path)\n",
        "    assert torch.allclose(expected, returned, rtol=1e-03, atol=1e-06), \"Wrong prediction returned!\"\n",
        "\n",
        "    # **** Second dataset ****\n",
        "    input_dataset = utils.get_classification_dataset_2d()\n",
        "    lr = lr_cls(2)\n",
        "    lr.fit(input_dataset.data, input_dataset.target, lr=1e-2, num_steps=int(1e4))\n",
        "    returned = lr.predict(input_dataset.data)\n",
        "    save_path = \".checker/04/lr_dataset_2d.out.torch\"\n",
        "    # torch.save(returned, save_path)\n",
        "    expected = torch.load(save_path)\n",
        "    assert torch.allclose(expected, returned, rtol=1e-03, atol=1e-06), \"Wrong prediction returned!\"\n",
        "\n",
        "    returned = lr.predict_proba(input_dataset.data)\n",
        "    save_path = \".checker/04/lr_dataset_2d_proba.out.torch\"\n",
        "    # torch.save(returned, save_path)\n",
        "    expected = torch.load(save_path)\n",
        "    assert torch.allclose(expected, returned, rtol=1e-03, atol=1e-06), \"Wrong prediction returned!\"\n",
        "\n",
        "    returned = lr.predict(input_dataset.data)\n",
        "    save_path = \".checker/04/lr_dataset_2d_preds.out.torch\"\n",
        "    # torch.save(returned, save_path)\n",
        "    expected = torch.load(save_path)\n",
        "    assert torch.allclose(expected, returned, rtol=1e-03, atol=1e-06), \"Wrong prediction returned!\"\n",
        "\n",
        "\n",
        "def optim_f(w: torch.Tensor) -> torch.Tensor:\n",
        "    x = torch.tensor([0.2, 2], dtype=torch.float)\n",
        "    return torch.sum(x * w ** 2)\n",
        "\n",
        "\n",
        "def optim_g(w: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
        "    x = torch.tensor([0.2, 2], dtype=torch.float)\n",
        "    return torch.sum(x * w + b)\n",
        "\n",
        "\n",
        "opt_checker_1 = SimpleNamespace(\n",
        "    f=optim_f, params=[torch.tensor([-6, 2], dtype=torch.float, requires_grad=True)]\n",
        ")\n",
        "opt_checker_2 = SimpleNamespace(\n",
        "    f=optim_g,\n",
        "    params=[\n",
        "        torch.tensor([-6, 2], dtype=torch.float, requires_grad=True),\n",
        "        torch.tensor([1, -1], dtype=torch.float, requires_grad=True),\n",
        "    ],\n",
        ")\n",
        "\n",
        "test_params = {\n",
        "    \"Momentum\": {\n",
        "        \"torch_cls\": SGD,\n",
        "        \"torch_params\": {\"lr\": 0.1, \"momentum\": 0.9},\n",
        "        \"params\": {\"learning_rate\": 0.1, \"gamma\": 0.9},\n",
        "    },\n",
        "    \"Adagrad\": {\n",
        "        \"torch_cls\": torch_adagrad,\n",
        "        \"torch_params\": {\"lr\": 0.5, \"eps\": 1e-8},\n",
        "        \"params\": {\"learning_rate\": 0.5, \"epsilon\": 1e-8},\n",
        "    },\n",
        "    \"RMSProp\": {\n",
        "        \"torch_cls\": torch_rmsprop,\n",
        "        \"torch_params\": {\n",
        "            \"lr\": 0.5,\n",
        "            \"alpha\": 0.9,\n",
        "            \"eps\": 1e-08,\n",
        "        },\n",
        "        \"params\": {\"learning_rate\": 0.5, \"gamma\": 0.9, \"epsilon\": 1e-8},\n",
        "    },\n",
        "    \"Adadelta\": {\n",
        "        \"torch_cls\": torch_adadelta,\n",
        "        \"torch_params\": {\"rho\": 0.9, \"eps\": 1e-1},\n",
        "        \"params\": {\"gamma\": 0.9, \"epsilon\": 1e-1},\n",
        "    },\n",
        "    \"Adam\": {\n",
        "        \"torch_cls\": torch_adam,\n",
        "        \"torch_params\": {\"lr\": 0.5, \"betas\": (0.9, 0.999), \"eps\": 1e-08},\n",
        "        \"params\": {\"learning_rate\": 0.5, \"beta1\": 0.9, \"beta2\": 0.999, \"epsilon\": 1e-8},\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "def test_optimizer(optim_cls: Type, num_steps: int = 10) -> None:\n",
        "    test_dict = test_params[optim_cls.__name__]\n",
        "\n",
        "    for ns in [opt_checker_1, opt_checker_2]:\n",
        "        torch_params = [p.clone().detach().requires_grad_(True) for p in ns.params]\n",
        "        torch_opt = test_dict[\"torch_cls\"](torch_params, **test_dict[\"torch_params\"])\n",
        "        for _ in range(num_steps):\n",
        "            torch_opt.zero_grad()\n",
        "\n",
        "            loss = ns.f(*torch_params)\n",
        "            loss.backward()\n",
        "            torch_opt.step()\n",
        "\n",
        "        params = [p.clone().detach().requires_grad_(True) for p in ns.params]\n",
        "        opt = optim_cls(params, **test_dict[\"params\"])\n",
        "\n",
        "        for _ in range(num_steps):\n",
        "            opt.zero_grad()\n",
        "\n",
        "            loss = ns.f(*params)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        for p, tp in zip(params, torch_params):\n",
        "            assert torch.allclose(p, tp)\n",
        "\n",
        "\n",
        "def test_droput(dropout_cls: Type) -> None:\n",
        "    drop = dropout_cls(0.5)\n",
        "    drop.train()\n",
        "    x = torch.randn(10, 30)\n",
        "    out = drop(x)\n",
        "\n",
        "    for row, orig_row in zip(out, x):\n",
        "        zeros_in_row = torch.where(row == 0.0)[0]\n",
        "        non_zeros_in_row = torch.where(row != 0.0)[0]\n",
        "        non_zeros_scaled = (row[non_zeros_in_row] == 2 * orig_row[non_zeros_in_row]).all()\n",
        "        assert len(zeros_in_row) > 0 and len(zeros_in_row) < len(row) and non_zeros_scaled\n",
        "\n",
        "    drop_eval = dropout_cls(0.5)\n",
        "    drop_eval.eval()\n",
        "    x = torch.randn(10, 30)\n",
        "    out_eval = drop_eval(x)\n",
        "\n",
        "    for row in out_eval:\n",
        "        zeros_in_row = len(torch.where(row == 0.0)[0])\n",
        "        assert zeros_in_row == 0\n",
        "\n",
        "\n",
        "def test_bn(bn_cls: Type) -> None:\n",
        "    torch.manual_seed(42)\n",
        "    bn = bn_cls(num_features=100)\n",
        "\n",
        "    opt = torch.optim.SGD(bn.parameters(), lr=0.1)\n",
        "\n",
        "    bn.train()\n",
        "    x = torch.rand(20, 100)\n",
        "    out = bn(x)\n",
        "\n",
        "    assert out.mean().abs().item() < 1e-4\n",
        "    assert abs(out.var().item() - 1) < 1e-1\n",
        "\n",
        "    assert (bn.sigma != 1).all()\n",
        "    assert (bn.mu != 1).all()\n",
        "\n",
        "    loss = 1 - out.mean()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    assert (bn.beta != 0).all()\n",
        "\n",
        "    n_steps = 10\n",
        "\n",
        "    for i in range(n_steps):\n",
        "        x = torch.rand(20, 100)\n",
        "        out = bn(x)\n",
        "        loss = 1 - out.mean()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    torch.manual_seed(43)\n",
        "    test_x = torch.randn(20, 100)\n",
        "    bn.eval()\n",
        "    test_out = bn(test_x)\n",
        "\n",
        "    assert abs(test_out.mean() + 0.5) < 1e-1\n",
        "\n",
        "\n",
        "expected_mean_readout = torch.tensor(\n",
        "    [[-0.0035, 0.0505, -0.2221, 0.1404, 0.1922, -0.3736, -0.0672, 0.0752,\n",
        "      -0.0613, 0.0439, -0.1307, -0.0752, -0.0310, 0.0081, -0.0553, -0.1734],\n",
        "     [-0.0054, -0.0144, -0.3113, 0.1665, 0.0738, -0.3303, 0.0420, 0.0668,\n",
        "      0.0494, 0.2648, -0.0478, 0.0550, -0.1923, -0.0157, 0.0508, 0.0148],\n",
        "     [-0.1912, 0.0309, -0.1512, 0.1283, 0.1120, -0.4540, -0.0644, 0.1378,\n",
        "      -0.0194, 0.0103, -0.1713, 0.0175, -0.0604, -0.0193, -0.0208, -0.0822]]\n",
        ")\n",
        "expected_attention_readout = torch.Tensor(\n",
        "    [[-0.0083, 0.0499, -0.2197, 0.1380, 0.1921, -0.3753, -0.0669, 0.0771,\n",
        "      -0.0592, 0.0411, -0.1317, -0.0769, -0.0299, 0.0074, -0.0568, -0.1741],\n",
        "     [-0.0068, -0.0131, -0.3102, 0.1656, 0.0736, -0.3312, 0.0410, 0.0670,\n",
        "      0.0485, 0.2635, -0.0479, 0.0544, -0.1933, -0.0162, 0.0508, 0.0150],\n",
        "     [-0.1911, 0.0308, -0.1514, 0.1271, 0.1100, -0.4542, -0.0658, 0.1376,\n",
        "      -0.0215, 0.0099, -0.1723, 0.0164, -0.0618, -0.0209, -0.0217, -0.0817]],\n",
        ")\n",
        "expected_sage_layer_output = torch.tensor(\n",
        "    [[-5.0965e-01, -4.5482e-01, -8.1451e-01, 5.4286e-03],\n",
        "     [-5.6737e-01, -5.9137e-01, -7.9304e-01, 7.5955e-02],\n",
        "     [-4.6768e-01, -5.0346e-01, -7.2765e-01, 5.0357e-02],\n",
        "     [-6.4185e-01, -5.0983e-01, -8.6305e-01, 1.3008e-02],\n",
        "     [-5.0465e-01, -3.5816e-01, -8.7864e-01, -3.1902e-02],\n",
        "     [-5.6591e-01, -4.2403e-01, -8.7506e-01, 2.9357e-02],\n",
        "     [-6.4185e-01, -5.0983e-01, -8.6305e-01, 1.3008e-02],\n",
        "     [-5.7196e-01, -3.5674e-01, -9.4769e-01, -4.9931e-03],\n",
        "     [-6.4185e-01, -5.0983e-01, -8.6305e-01, 1.3008e-02],\n",
        "     [-5.2655e-01, -5.1094e-01, -8.3806e-01, -1.8521e-02],\n",
        "     [-6.4185e-01, -5.0983e-01, -8.6305e-01, 1.3008e-02],\n",
        "     [-5.7628e-01, -5.5394e-01, -8.7300e-01, -7.6976e-03],\n",
        "     [-4.6768e-01, -5.0346e-01, -7.2765e-01, 5.0357e-02],\n",
        "     [-5.4808e-01, -5.3204e-01, -7.8906e-01, 4.2878e-02],\n",
        "     [-5.3417e-01, -3.5912e-01, -9.5030e-01, 2.3648e-05],\n",
        "     [-6.2538e-01, -2.9249e-01, -1.1233e+00, 1.0970e-01],\n",
        "     [-6.5214e-01, -3.8342e-01, -1.0136e+00, -1.6424e-02],\n",
        "     [-6.5214e-01, -3.8342e-01, -1.0136e+00, -1.6424e-02]],\n",
        ")\n",
        "expected_gin_layer_output = torch.tensor(\n",
        "    [[-0.4516, -0.3673, -0.5313, 0.3170],\n",
        "     [-0.4524, -0.3760, -0.5243, 0.3249],\n",
        "     [-0.4570, -0.3747, -0.5313, 0.3221],\n",
        "     [-0.4763, -0.4030, -0.5390, 0.3335],\n",
        "     [-0.4481, -0.3855, -0.5187, 0.3295],\n",
        "     [-0.4545, -0.3838, -0.5245, 0.3276],\n",
        "     [-0.4763, -0.4030, -0.5390, 0.3335],\n",
        "     [-0.4390, -0.4001, -0.4973, 0.3446],\n",
        "     [-0.4763, -0.4030, -0.5390, 0.3335],\n",
        "     [-0.4683, -0.3882, -0.5400, 0.3248],\n",
        "     [-0.4763, -0.4030, -0.5390, 0.3335],\n",
        "     [-0.4682, -0.3921, -0.5374, 0.3277],\n",
        "     [-0.4570, -0.3747, -0.5313, 0.3221],\n",
        "     [-0.4225, -0.3671, -0.4928, 0.3295],\n",
        "     [-0.3760, -0.3700, -0.4407, 0.3489],\n",
        "     [-0.2646, -0.3342, -0.3357, 0.3683],\n",
        "     [-0.3859, -0.3950, -0.4392, 0.3624],\n",
        "     [-0.3859, -0.3950, -0.4392, 0.3624]],\n",
        ")\n",
        "expected_simple_mpnn_output = torch.tensor(\n",
        "    [[-0.1990, -0.2007, -0.7749, -0.2355],\n",
        "     [-0.5297, -0.4750, -0.8783, -0.0762],\n",
        "     [-0.3664, -0.4155, -0.7463, -0.0573],\n",
        "     [-0.5217, -0.3488, -0.9198, -0.1840],\n",
        "     [0.1237, -0.0524, -0.5546, -0.1867],\n",
        "     [-0.3597, -0.2378, -0.8626, -0.1551],\n",
        "     [-0.5217, -0.3488, -0.9198, -0.1840],\n",
        "     [-0.3358, -0.2634, -0.8318, -0.0586],\n",
        "     [-0.5217, -0.3488, -0.9198, -0.1840],\n",
        "     [-0.2175, -0.2724, -0.7910, -0.2460],\n",
        "     [-0.5217, -0.3488, -0.9198, -0.1840],\n",
        "     [-0.3758, -0.3293, -0.9195, -0.2665],\n",
        "     [-0.3664, -0.4155, -0.7463, -0.0573],\n",
        "     [-0.3907, -0.4223, -0.7682, -0.0586],\n",
        "     [-0.2049, -0.2482, -0.7605, -0.0309],\n",
        "     [-0.1718, 0.0814, -1.0231, -0.2095],\n",
        "     [-0.3551, -0.2676, -0.8502, -0.0614],\n",
        "     [-0.3551, -0.2676, -0.8502, -0.0614]]\n",
        ")\n",
        "expected_sum_readout = torch.tensor(\n",
        "    [[-0.0451, 0.6570, -2.8874, 1.8256, 2.4987, -4.8573, -0.8733, 0.9780,\n",
        "      -0.7967, 0.5701, -1.6988, -0.9777, -0.4033, 0.1053, -0.7191, -2.2545],\n",
        "     [-0.0268, -0.0720, -1.5565, 0.8324, 0.3692, -1.6515, 0.2101, 0.3342,\n",
        "      0.2468, 1.3238, -0.2389, 0.2752, -0.9615, -0.0785, 0.2541, 0.0741],\n",
        "     [-0.9559, 0.1545, -0.7560, 0.6414, 0.5598, -2.2701, -0.3222, 0.6888,\n",
        "      -0.0969, 0.0516, -0.8565, 0.0875, -0.3022, -0.0964, -0.1039, -0.4109]],\n",
        ")\n",
        "expected_gine_layer_output = torch.tensor(\n",
        "    [[-0.4519, -0.3654, -0.5197, 0.3193],\n",
        "     [-0.4577, -0.3681, -0.5309, 0.3200],\n",
        "     [-0.4617, -0.3697, -0.5356, 0.3193],\n",
        "     [-0.4318, -0.3586, -0.5039, 0.3215],\n",
        "     [-0.3675, -0.3206, -0.4476, 0.3215],\n",
        "     [-0.4474, -0.3725, -0.5134, 0.3252],\n",
        "     [-0.4318, -0.3586, -0.5039, 0.3215],\n",
        "     [-0.4617, -0.3816, -0.5311, 0.3244],\n",
        "     [-0.4318, -0.3586, -0.5039, 0.3215],\n",
        "     [-0.3174, -0.2810, -0.4102, 0.3140],\n",
        "     [-0.4318, -0.3586, -0.5039, 0.3215],\n",
        "     [-0.3173, -0.2847, -0.4078, 0.3168],\n",
        "     [-0.4617, -0.3697, -0.5356, 0.3193],\n",
        "     [-0.4367, -0.3529, -0.5122, 0.3167],\n",
        "     [-0.4103, -0.3570, -0.4806, 0.3282],\n",
        "     [-0.4105, -0.3539, -0.4767, 0.3282],\n",
        "     [-0.4575, -0.3899, -0.5207, 0.3318],\n",
        "     [-0.4575, -0.3899, -0.5207, 0.3318]]\n",
        ")\n",
        "expected_gat_output = torch.tensor(\n",
        "    [[0.2640, 0.0480, 0.0950, -0.0174, -0.2840, 0.0064, 0.0522, -0.1773,\n",
        "      0.1720, 0.1878, -0.1340, 0.0229],\n",
        "     [0.1955, 0.0230, 0.0520, 0.0308, -0.2525, 0.0519, 0.0259, -0.1553,\n",
        "      0.1808, 0.1965, -0.1323, 0.0663],\n",
        "     [0.2423, 0.0486, 0.1118, -0.0467, -0.2726, 0.0444, 0.0325, -0.1617,\n",
        "      0.1654, 0.1770, -0.1465, 0.0071],\n",
        "     [0.2717, 0.0307, 0.0516, 0.1657, -0.2802, -0.1184, 0.1700, -0.1849,\n",
        "      0.2089, 0.2373, -0.1915, -0.0212],\n",
        "     [0.2887, -0.0457, 0.2075, 0.0216, -0.2877, -0.0890, 0.1351, -0.1585,\n",
        "      0.2169, 0.1446, -0.0779, 0.0065],\n",
        "     [0.2594, -0.0098, 0.0917, 0.0416, -0.2764, -0.0409, 0.1162, -0.1622,\n",
        "      0.1887, 0.1710, -0.1145, 0.0457],\n",
        "     [0.2717, 0.0307, 0.0516, 0.1657, -0.2802, -0.1184, 0.1700, -0.1849,\n",
        "      0.2089, 0.2373, -0.1915, -0.0212],\n",
        "     [0.2488, -0.0431, 0.1990, 0.0435, -0.2735, -0.0590, 0.0793, -0.1624,\n",
        "      0.2314, 0.1686, -0.0642, 0.0281],\n",
        "     [0.2717, 0.0307, 0.0516, 0.1657, -0.2802, -0.1184, 0.1700, -0.1849,\n",
        "      0.2089, 0.2373, -0.1915, -0.0212],\n",
        "     [0.2924, 0.0171, 0.0866, 0.1376, -0.2914, -0.1295, 0.1688, -0.1878,\n",
        "      0.2136, 0.2186, -0.1574, -0.0087],\n",
        "     [0.2717, 0.0307, 0.0516, 0.1657, -0.2802, -0.1184, 0.1700, -0.1849,\n",
        "      0.2089, 0.2373, -0.1915, -0.0212],\n",
        "     [0.2485, 0.0049, 0.0737, 0.1471, -0.2700, -0.0880, 0.1455, -0.1686,\n",
        "      0.2142, 0.2180, -0.1624, 0.0050],\n",
        "     [0.2423, 0.0486, 0.1118, -0.0467, -0.2726, 0.0444, 0.0325, -0.1617,\n",
        "      0.1654, 0.1770, -0.1465, 0.0071],\n",
        "     [0.1620, 0.0681, 0.0655, -0.0755, -0.2404, 0.0517, -0.0479, -0.1210,\n",
        "      0.1310, 0.2535, -0.1107, 0.0330],\n",
        "     [0.1185, -0.0203, 0.1807, -0.1225, -0.2394, 0.0383, -0.0468, -0.0771,\n",
        "      0.1557, 0.2144, -0.0754, 0.0079],\n",
        "     [0.1485, -0.0095, 0.1458, -0.0414, -0.2376, 0.0539, -0.0255, -0.1200,\n",
        "      0.1828, 0.2043, -0.0969, 0.0238],\n",
        "     [0.1268, -0.0224, 0.1846, -0.0438, -0.2185, 0.0215, -0.0412, -0.0883,\n",
        "      0.1823, 0.2223, -0.0525, 0.0223],\n",
        "     [0.1268, -0.0224, 0.1846, -0.0438, -0.2185, 0.0215, -0.0412, -0.0883,\n",
        "      0.1823, 0.2223, -0.0525, 0.0223]]\n",
        ")\n",
        "expected_dot_attention_output = torch.tensor(\n",
        "    [[[0.247395, 0.028085, 0.077167, 0.078323, -0.272530, -0.039541,\n",
        "       0.097621, -0.173803, 0.194980, 0.212308, -0.155935, 0.009429],\n",
        "      [0.247197, 0.028359, 0.076629, 0.078957, -0.272447, -0.039580,\n",
        "       0.097599, -0.173896, 0.195020, 0.212726, -0.156340, 0.009328],\n",
        "      [0.247197, 0.028359, 0.076629, 0.078957, -0.272447, -0.039580,\n",
        "       0.097599, -0.173896, 0.195020, 0.212726, -0.156340, 0.009328],\n",
        "      [0.247205, 0.028425, 0.076465, 0.079172, -0.272451, -0.039678,\n",
        "       0.097692, -0.173931, 0.195030, 0.212829, -0.156458, 0.009298],\n",
        "      [0.247366, 0.028181, 0.077058, 0.078077, -0.272529, -0.039312,\n",
        "       0.097431, -0.173821, 0.194880, 0.212299, -0.155915, 0.009523],\n",
        "      [0.247294, 0.028266, 0.076776, 0.078823, -0.272488, -0.039640,\n",
        "       0.097682, -0.173873, 0.195015, 0.212599, -0.156228, 0.009356],\n",
        "      [0.247205, 0.028425, 0.076465, 0.079172, -0.272451, -0.039678,\n",
        "       0.097692, -0.173931, 0.195030, 0.212829, -0.156458, 0.009298],\n",
        "      [0.247267, 0.028328, 0.076711, 0.078774, -0.272479, -0.039554,\n",
        "       0.097609, -0.173882, 0.194982, 0.212625, -0.156263, 0.009363],\n",
        "      [0.247205, 0.028425, 0.076465, 0.079172, -0.272451, -0.039678,\n",
        "       0.097692, -0.173931, 0.195030, 0.212829, -0.156458, 0.009298],\n",
        "      [0.247439, 0.028163, 0.077091, 0.078058, -0.272561, -0.039385,\n",
        "       0.097505, -0.173831, 0.194878, 0.212268, -0.155892, 0.009516],\n",
        "      [0.247205, 0.028425, 0.076465, 0.079172, -0.272451, -0.039678,\n",
        "       0.097692, -0.173931, 0.195030, 0.212829, -0.156458, 0.009298],\n",
        "      [0.247439, 0.028163, 0.077091, 0.078058, -0.272561, -0.039385,\n",
        "       0.097505, -0.173831, 0.194878, 0.212268, -0.155892, 0.009516],\n",
        "      [0.247197, 0.028359, 0.076629, 0.078957, -0.272447, -0.039580,\n",
        "       0.097599, -0.173896, 0.195020, 0.212726, -0.156340, 0.009328]],\n",
        "\n",
        "     [[0.149018, -0.009261, 0.146324, -0.040262, -0.237542, 0.053946,\n",
        "       -0.025190, -0.120178, 0.182961, 0.204468, -0.097441, 0.023849],\n",
        "      [0.148795, -0.009539, 0.146771, -0.040582, -0.237508, 0.053813,\n",
        "       -0.025267, -0.119906, 0.182963, 0.204425, -0.097220, 0.023744],\n",
        "      [0.148841, -0.009706, 0.146875, -0.040337, -0.237519, 0.053888,\n",
        "       -0.025151, -0.120024, 0.183147, 0.204257, -0.097275, 0.023751],\n",
        "      [0.148969, -0.009118, 0.146230, -0.040569, -0.237560, 0.053904,\n",
        "       -0.025295, -0.120064, 0.182772, 0.204599, -0.097426, 0.023824],\n",
        "      [0.148969, -0.009118, 0.146230, -0.040569, -0.237560, 0.053904,\n",
        "       -0.025295, -0.120064, 0.182772, 0.204599, -0.097426, 0.023824],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000]]]\n",
        ")\n",
        "sub_optimal_multihead_attention_output = torch.tensor(\n",
        "    [[[-0.047262, 0.158078, -0.034781, -0.059588, -0.184203, 0.316856,\n",
        "       -0.051797, -0.067320, 0.136281, 0.157510, -0.516869, -0.168178],\n",
        "      [-0.047338, 0.158081, -0.034847, -0.059696, -0.184200, 0.316798,\n",
        "       -0.051846, -0.067277, 0.136283, 0.157549, -0.516819, -0.168149],\n",
        "      [-0.047338, 0.158081, -0.034847, -0.059696, -0.184200, 0.316798,\n",
        "       -0.051846, -0.067277, 0.136283, 0.157549, -0.516819, -0.168149],\n",
        "      [-0.047268, 0.158293, -0.035019, -0.059606, -0.184036, 0.316881,\n",
        "       -0.051766, -0.067249, 0.136248, 0.157471, -0.516841, -0.168100],\n",
        "      [-0.047252, 0.158166, -0.034837, -0.059572, -0.184190, 0.316919,\n",
        "       -0.051814, -0.067332, 0.136266, 0.157541, -0.516920, -0.168195],\n",
        "      [-0.047393, 0.158178, -0.035001, -0.059744, -0.184167, 0.316858,\n",
        "       -0.051927, -0.067270, 0.136275, 0.157615, -0.516819, -0.168113],\n",
        "      [-0.047268, 0.158293, -0.035019, -0.059606, -0.184036, 0.316881,\n",
        "       -0.051766, -0.067249, 0.136248, 0.157471, -0.516841, -0.168100],\n",
        "      [-0.047321, 0.158228, -0.034976, -0.059684, -0.184134, 0.316867,\n",
        "       -0.051861, -0.067273, 0.136249, 0.157590, -0.516864, -0.168169],\n",
        "      [-0.047268, 0.158293, -0.035019, -0.059606, -0.184036, 0.316881,\n",
        "       -0.051766, -0.067249, 0.136248, 0.157471, -0.516841, -0.168100],\n",
        "      [-0.047309, 0.158097, -0.034834, -0.059547, -0.184185, 0.316923,\n",
        "       -0.051868, -0.067345, 0.136356, 0.157493, -0.516793, -0.168035],\n",
        "      [-0.047268, 0.158293, -0.035019, -0.059606, -0.184036, 0.316881,\n",
        "       -0.051766, -0.067249, 0.136248, 0.157471, -0.516841, -0.168100],\n",
        "      [-0.047309, 0.158097, -0.034834, -0.059547, -0.184185, 0.316923,\n",
        "       -0.051868, -0.067345, 0.136356, 0.157493, -0.516793, -0.168035],\n",
        "      [-0.047338, 0.158081, -0.034847, -0.059696, -0.184200, 0.316798,\n",
        "       -0.051846, -0.067277, 0.136283, 0.157549, -0.516819, -0.168149]],\n",
        "\n",
        "     [[-0.065048, 0.168032, -0.084588, -0.057781, -0.217642, 0.305161,\n",
        "       -0.096480, -0.093513, 0.154069, 0.215230, -0.510000, -0.149824],\n",
        "      [-0.065092, 0.168042, -0.084506, -0.057821, -0.217695, 0.305299,\n",
        "       -0.096637, -0.093606, 0.154123, 0.215237, -0.510100, -0.149899],\n",
        "      [-0.065017, 0.168049, -0.084602, -0.057950, -0.217689, 0.305254,\n",
        "       -0.096547, -0.093616, 0.154084, 0.215219, -0.510125, -0.149970],\n",
        "      [-0.065047, 0.168035, -0.084817, -0.057796, -0.217683, 0.305158,\n",
        "       -0.096428, -0.093492, 0.153998, 0.215284, -0.509987, -0.149702],\n",
        "      [-0.065047, 0.168035, -0.084817, -0.057796, -0.217683, 0.305158,\n",
        "       -0.096428, -0.093492, 0.153998, 0.215284, -0.509987, -0.149702],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000]]]\n",
        ")\n",
        "expected_multihead_attention_output = torch.tensor(\n",
        "    [[[-0.200755, -0.260959, 0.024996, -0.159938, -0.117561, -0.155180,\n",
        "       -0.118139, -0.045920, 0.259167, 0.172350, -0.112809, 0.000357],\n",
        "      [-0.095821, -0.200517, -0.044585, -0.245520, -0.105037, -0.087925,\n",
        "       -0.114011, -0.138533, 0.175087, 0.122279, -0.243832, -0.062268],\n",
        "      [-0.095821, -0.200517, -0.044585, -0.245520, -0.105037, -0.087925,\n",
        "       -0.114011, -0.138533, 0.175087, 0.122279, -0.243832, -0.062268],\n",
        "      [-0.052662, -0.286963, -0.057362, -0.221366, -0.107536, -0.107964,\n",
        "       -0.254695, -0.186610, 0.313417, 0.165387, -0.220242, -0.075458],\n",
        "      [-0.162727, -0.270804, 0.014429, -0.124464, -0.043585, -0.150952,\n",
        "       -0.160673, -0.101641, 0.258712, 0.126690, -0.086178, 0.005115],\n",
        "      [-0.142106, -0.245964, -0.061551, -0.185489, -0.082154, -0.078331,\n",
        "       -0.108871, -0.160405, 0.274722, 0.203109, -0.137307, -0.037420],\n",
        "      [-0.052662, -0.286963, -0.057362, -0.221366, -0.107536, -0.107964,\n",
        "       -0.254695, -0.186610, 0.313417, 0.165387, -0.220242, -0.075458],\n",
        "      [-0.163393, -0.247003, -0.065559, -0.170543, -0.109216, -0.102695,\n",
        "       -0.102142, -0.125409, 0.295476, 0.250740, -0.140760, -0.024756],\n",
        "      [-0.052662, -0.286963, -0.057362, -0.221366, -0.107536, -0.107964,\n",
        "       -0.254695, -0.186610, 0.313417, 0.165387, -0.220242, -0.075458],\n",
        "      [-0.177342, -0.279195, 0.035479, -0.132536, -0.025988, -0.143513,\n",
        "       -0.184524, -0.091127, 0.269926, 0.090618, -0.080655, 0.007161],\n",
        "      [-0.052662, -0.286963, -0.057362, -0.221366, -0.107536, -0.107964,\n",
        "       -0.254695, -0.186610, 0.313417, 0.165387, -0.220242, -0.075458],\n",
        "      [-0.177342, -0.279195, 0.035479, -0.132536, -0.025988, -0.143513,\n",
        "       -0.184524, -0.091127, 0.269926, 0.090618, -0.080655, 0.007161],\n",
        "      [-0.095821, -0.200517, -0.044585, -0.245520, -0.105037, -0.087925,\n",
        "       -0.114011, -0.138533, 0.175087, 0.122279, -0.243832, -0.062268]],\n",
        "\n",
        "     [[-0.095821, -0.200517, -0.044585, -0.245520, -0.105037, -0.087925,\n",
        "       -0.114011, -0.138533, 0.175087, 0.122279, -0.243832, -0.062268],\n",
        "      [-0.178757, -0.240222, -0.038666, -0.193246, -0.126989, -0.105094,\n",
        "       -0.065300, -0.063201, 0.250495, 0.208277, -0.178849, -0.007677],\n",
        "      [-0.150638, -0.238185, -0.068680, -0.149003, -0.092437, -0.140781,\n",
        "       -0.076493, -0.075186, 0.247676, 0.200479, -0.141489, 0.012234],\n",
        "      [-0.163393, -0.247003, -0.065559, -0.170543, -0.109216, -0.102695,\n",
        "       -0.102142, -0.125409, 0.295476, 0.250740, -0.140760, -0.024756],\n",
        "      [-0.163393, -0.247003, -0.065559, -0.170543, -0.109216, -0.102695,\n",
        "       -0.102142, -0.125409, 0.295476, 0.250740, -0.140760, -0.024756],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000],\n",
        "      [0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000,\n",
        "       0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000]]]\n",
        ")"
      ],
      "metadata": {
        "id": "R_aX30dmGhpj"
      },
      "id": "R_aX30dmGhpj",
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b6a601dc47074ca6"
      },
      "id": "b6a601dc47074ca6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer"
      ],
      "metadata": {
        "collapsed": false,
        "id": "be6593567ea5467"
      },
      "id": "be6593567ea5467"
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "from tqdm.autonotebook import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from torchmetrics import Metric\n",
        "from dgl.data import Subset\n",
        "from torch import nn\n",
        "from typing import Type\n",
        "from typing import Dict, Any\n",
        "from pathlib import Path\n",
        "from abc import ABC, abstractmethod\n",
        "# from lab.checker import expected_mean_readout, expected_gin_layer_output, expected_sage_layer_output, \\\n",
        "#     expected_attention_readout, expected_gine_layer_output, expected_sum_readout, expected_simple_mpnn_output\n",
        "\n",
        "\n",
        "class LoggerBase(ABC):\n",
        "    def __init__(self, logdir: str | Path):\n",
        "        self.logdir = Path(logdir)\n",
        "        self.logdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    @abstractmethod\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def close(self):\n",
        "        ...\n",
        "\n",
        "\n",
        "class DummyLogger(LoggerBase):  # If you don't want to use any logger, you can use this one\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "    def restart(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class MetricList:\n",
        "    def __init__(self, metrics: Dict[str, Metric]):\n",
        "        self.metrics = copy.deepcopy(metrics)\n",
        "\n",
        "    def update(self, preds: torch.Tensor, targets: torch.Tensor) -> None:\n",
        "        for name, metric in self.metrics.items():\n",
        "            metric.update(preds.detach().cpu(), targets.cpu())\n",
        "\n",
        "    def compute(self) -> Dict[str, float]:\n",
        "        metrics = {}\n",
        "        for name, metric_fn in self.metrics.items():\n",
        "            metrics[name] = metric_fn.compute().item()\n",
        "            metric_fn.reset()\n",
        "        return metrics\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(\n",
        "            self,\n",
        "            *,\n",
        "            run_dir: str | Path,\n",
        "            train_dataset: Subset,\n",
        "            valid_dataset: Subset,\n",
        "            train_metrics: Dict[str, Metric],\n",
        "            valid_metrics: Dict[str, Metric],\n",
        "            model: nn.Module,\n",
        "            logger: LoggerBase,\n",
        "            optimizer_kwargs: Dict[str, Any],\n",
        "            optimizer_cls: Type[torch.optim.Optimizer] = torch.optim.Adam,\n",
        "            n_epochs: int,\n",
        "            train_batch_size: int = 32,\n",
        "            valid_batch_size: int = 16,\n",
        "            device: str = \"cuda\",\n",
        "            valid_every_n_epochs: int = 1,\n",
        "            loss_fn=nn.MSELoss()\n",
        "    ):\n",
        "        self.run_dir = Path(run_dir)\n",
        "        self.train_loader = GraphDataLoader(\n",
        "            dataset=train_dataset,\n",
        "            batch_size=train_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        self.valid_loader = GraphDataLoader(\n",
        "            dataset=valid_dataset,\n",
        "            batch_size=valid_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        self.train_metrics = MetricList(train_metrics)\n",
        "        self.valid_metrics = MetricList(valid_metrics)\n",
        "        self.logger = logger\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer_cls(model.parameters(), **optimizer_kwargs)\n",
        "        self.n_epochs = n_epochs\n",
        "        self.device = device\n",
        "        self.valid_every_n_epochs = valid_every_n_epochs\n",
        "        self.loss_fn = loss_fn\n",
        "        self.model.to(device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, dataloader: GraphDataLoader, prefix: str) -> Dict[str, float]:\n",
        "        previous_mode = self.model.training\n",
        "        self.model.eval()\n",
        "        losses = []\n",
        "        for _, graphs, labels in dataloader:\n",
        "            graphs = graphs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            preds = self.model(graphs)\n",
        "            loss = self.loss_fn(preds, labels)\n",
        "            losses.append(loss.item())\n",
        "            self.valid_metrics.update(preds, labels)\n",
        "        self.model.train(mode=previous_mode)\n",
        "        metrics = {\"loss\": np.mean(losses)} | self.valid_metrics.compute()\n",
        "        self.logger.log_metrics(metrics=metrics, prefix=prefix)\n",
        "        return metrics\n",
        "\n",
        "    def train(self) -> Dict[str, float]:\n",
        "        self.model.train()\n",
        "        valid_metrics = {}\n",
        "        for epoch in tqdm(range(self.n_epochs), total=self.n_epochs):\n",
        "            for _, graphs, labels in self.train_loader:\n",
        "                self.optimizer.zero_grad()\n",
        "                graphs = graphs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                preds = self.model(graphs)\n",
        "                loss = self.loss_fn(preds, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                self.train_metrics.update(preds, labels)\n",
        "                train_metrics = {\"loss\": loss.item()} | self.train_metrics.compute()\n",
        "                self.logger.log_metrics(metrics=train_metrics, prefix=\"train\")\n",
        "\n",
        "                if epoch % self.valid_every_n_epochs == 0 or epoch == self.n_epochs - 1:\n",
        "                    valid_metrics = self.validate(self.valid_loader, prefix=\"valid\")\n",
        "\n",
        "        return valid_metrics\n",
        "\n",
        "    def test(self, dataset: Subset) -> Dict[str, float]:\n",
        "        dataloader = GraphDataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size=16,\n",
        "            shuffle=False,\n",
        "        )\n",
        "        return self.validate(dataloader, prefix=\"test\")\n",
        "\n",
        "    def close(self):  # close the logger, not really required for wandb\n",
        "        self.logger.close()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.674313Z",
          "start_time": "2023-12-11T15:15:49.633153Z"
        },
        "id": "e75cf00937a3c413"
      },
      "id": "e75cf00937a3c413"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neural Networks (GNNs)\n",
        "The high-level Graph Neural Network architecture we are going to use looks roughly like this:\n",
        "\n",
        "<img src=\"https://github.com/MariiaSaltykova/machine_learning/blob/main/resources/gnn.png?raw=1\" width=\"1200\" />\n",
        "\n",
        "- The Featurizer takes a molecule and transforms it to a graph with node and edge features (it happens at the level of dataset, so we don't really need to worry about that).\n",
        "- In our case, we will linearly embed the node and edge features to the hidden size before applying first MPNN layer which is not captured in the diagram.\n",
        "- The MPNN layer takes node (and possibly edge embeddings) and the graph structure and returns updated node embeddings. It happens in a loop.\n",
        "- Then the node embeddings are aggregated by the Readout layer to obtain a graph embeddings.\n",
        "- Finally, the graph embeddings are passed to the MLP to obtain the final prediction."
      ],
      "metadata": {
        "collapsed": false,
        "id": "7d54c9a1e68cd221"
      },
      "id": "7d54c9a1e68cd221"
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "outputs": [],
      "source": [
        "class MPNNLayerBase(ABC, nn.Module):\n",
        "    def _init(self, hidden_size: int):\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            hidden_size: the size of node (and edges) embeddings\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "\n",
        "class ReadoutBase(nn.Module):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 node_features_size: int,\n",
        "                 edge_features_size: int,\n",
        "                 hidden_size: int,\n",
        "                 output_size: int,\n",
        "                 mpnn_layer_cls: Type[MPNNLayerBase],\n",
        "                 mpnn_layer_kwargs: Dict[str, Any],\n",
        "                 mpnn_n_layers: int,\n",
        "                 readout_cls: Type[ReadoutBase]):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_features_size: the size of node features\n",
        "            edge_features_size: the size of edge features\n",
        "            hidden_size: the size of node (and edge) embeddings\n",
        "            output_size: the size of the final prediction\n",
        "            mpnn_layer_cls: the class of MPNN layer\n",
        "            mpnn_layer_kwargs: the kwargs for the MPNN layer\n",
        "            mpnn_n_layers: the number of MPNN layers\n",
        "            readout_cls: the class of Readout layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear_node = nn.Linear(node_features_size, hidden_size)\n",
        "        self.linear_edge = nn.Linear(edge_features_size, hidden_size)\n",
        "        self.mpnn_layers = nn.ModuleList([\n",
        "            mpnn_layer_cls(hidden_size=hidden_size, **mpnn_layer_kwargs)\n",
        "            for _ in range(mpnn_n_layers)\n",
        "        ])\n",
        "        self.readout = readout_cls(hidden_size=hidden_size)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, output_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            graph: a DGLGraph that contains the graph structure and node/edge features in a sparse format\n",
        "        Returns:\n",
        "            predictions: the final predictions\n",
        "        \"\"\"\n",
        "        node_embeddings, edge_embeddings = graph.ndata['h'], graph.edata['e']\n",
        "        node_embeddings = self.linear_node(node_embeddings)\n",
        "        edge_embeddings = self.linear_edge(\n",
        "            edge_embeddings)  # some of the models does not use edge features, but we won't use if-clauses for convenience.\n",
        "        for layer in self.mpnn_layers:\n",
        "            node_embeddings = layer(node_embeddings=node_embeddings, edge_embeddings=edge_embeddings, graph=graph)\n",
        "        graph_embedding = self.readout(node_embeddings, graph)\n",
        "        predictions = self.mlp(graph_embedding)\n",
        "        return predictions"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.674390Z",
          "start_time": "2023-12-11T15:15:49.638119Z"
        },
        "id": "e6e7df76cc963d8b"
      },
      "id": "e6e7df76cc963d8b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Readout\n",
        "Readout operation is used to aggregate node embeddings to obtain a graph embedding. There are many different readout operations, but the most popular are: sum, mean, attention, and max. We are going to implement the first three of them. Summing over nodes' embeddings seems trivial, but they're stored in a sparse format, meaning that all the nodes form all the graphs in a batch are stored in a one tensor of size `[num_nodes_1 + num_nodes_2 + ... + num_nodes_N, hidden_size]':   "
      ],
      "metadata": {
        "collapsed": false,
        "id": "b9ac59d947b4000b"
      },
      "id": "b9ac59d947b4000b"
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([23, 16]), tensor([13,  5,  5]))"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ],
      "source": [
        "batched_graph = dgl.batch([dataset[0][1], dataset[1][1], dataset[2][1]])\n",
        "linear = nn.Linear(node_featurizer.feat_size(), 16)\n",
        "node_embeddings = linear(batched_graph.ndata['h'])\n",
        "node_embeddings.shape, batched_graph.batch_num_nodes()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.675636Z",
          "start_time": "2023-12-11T15:15:49.641552Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "473300e58a6023b7",
        "outputId": "112621c7-b22e-476f-da6e-8e0c1711a01a"
      },
      "id": "473300e58a6023b7"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVww5A8yGx_d",
        "outputId": "91018266-241a-484b-857d-7b014d1fa0d5"
      },
      "id": "PVww5A8yGx_d",
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For simplicity, we will convert the sparse node embeddings to a dense format with padding. Then the shape of the node embeddings will be `[batch_size, max_num_nodes, hidden_size]`. We can use the `to_dense_batch` function from `torch_geometric` for that:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "fce302b7c444ae16"
      },
      "id": "fce302b7c444ae16"
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "\n",
        "\n",
        "def to_dense_embeddings(node_embeddings: torch.Tensor,\n",
        "                        graph: dgl.DGLGraph,\n",
        "                        fill_value: float = 0.0) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Converts sparse node embeddings to dense node embeddings with padding.\n",
        "    Arguments:\n",
        "        node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        graph: a batch of graphs\n",
        "        fill_value: a value to fill the padding with\n",
        "    Returns:\n",
        "        node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "        mask: a mask indicating which nodes are real and which are padding, i.e. [batch_size, max_num_nodes]\n",
        "    \"\"\"\n",
        "    num_nodes = graph.batch_num_nodes() # e.g. [2, 3, 3]\n",
        "    # print(num_nodes)\n",
        "    indices = torch.arange(len(num_nodes), device=num_nodes.device)\n",
        "    batch = torch.repeat_interleave(indices, num_nodes).long() # e.g. [0, 0, 1, 1, 1, 2, 2, 2]\n",
        "    # print(batch)\n",
        "    return to_dense_batch(node_embeddings, batch,\n",
        "                          fill_value=fill_value)  # that's the only reason we have torch_geometric in the requirements\n",
        "\n",
        "\n",
        "def to_sparse_embeddings(node_embeddings: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Converts dense node embeddings to sparse node embeddings.\n",
        "    Arguments:\n",
        "        node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "        mask: a mask indicating which nodes are real and which are padding, i.e. [batch_size, max_num_nodes]\n",
        "    Returns:\n",
        "        node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "    \"\"\"\n",
        "    return node_embeddings[mask]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.675719Z",
          "start_time": "2023-12-11T15:15:49.647698Z"
        },
        "id": "a3fd81a5384d2ad0"
      },
      "id": "a3fd81a5384d2ad0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can simply convert the node embeddings to a dense format and sum them $x = \\sum_i^n x_i$:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "4190f0ff3fa0ae1f"
      },
      "id": "4190f0ff3fa0ae1f"
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "outputs": [],
      "source": [
        "class SumReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        # We can also use dgl.sum_nodes function, but let assume it's forbidden in that notebook ;)\n",
        "        node_embeddings, _ = to_dense_embeddings(node_embeddings, graph)\n",
        "        return node_embeddings.sum(dim=1)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.675774Z",
          "start_time": "2023-12-11T15:15:49.651743Z"
        },
        "id": "841a8932a12397f3"
      },
      "id": "841a8932a12397f3"
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "outputs": [],
      "source": [
        "def test_readout(readout_cls: Type[ReadoutBase], expected_output: torch.Tensor):\n",
        "    torch.manual_seed(0)\n",
        "    graph = dgl.batch([dataset[0][1], dataset[1][1], dataset[2][1]])\n",
        "\n",
        "    linear = nn.Linear(node_featurizer.feat_size(), 16)\n",
        "    node_embeddings = linear(graph.ndata['h'])\n",
        "    readout = readout_cls(hidden_size=16)\n",
        "    result = readout(node_embeddings, graph)\n",
        "    print(torch.allclose(result, expected_output, atol=1e-3))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.675818Z",
          "start_time": "2023-12-11T15:15:49.656700Z"
        },
        "id": "447a28b93e6e8e89"
      },
      "id": "447a28b93e6e8e89"
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_readout(SumReadout, expected_sum_readout)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.737736Z",
          "start_time": "2023-12-11T15:15:49.659561Z"
        },
        "id": "b5dd5e1b3bbde2cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38abd5f8-b47e-45f0-88a8-77771a0c3124"
      },
      "id": "b5dd5e1b3bbde2cc"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import global_mean_pool"
      ],
      "metadata": {
        "id": "WHQ14lqCW-kn"
      },
      "id": "WHQ14lqCW-kn",
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1. Implement mean readout (1 point).\n",
        "Implement the mean readout given by formula $x = \\frac{1}{n}\\sum_i^n x_i$:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "579fd18386daaed"
      },
      "id": "579fd18386daaed"
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "class MeanReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        # Don't use any dlg functions here\n",
        "\n",
        "        node_embeddings, _ = to_dense_embeddings(node_embeddings, graph)\n",
        "        # res_custom = node_embeddings.mean(dim=1)\n",
        "        # res_torch = global_mean_pool(node_embeddings, batch=None)\n",
        "        # print(torch.allclose(res_custom, res_torch, atol=1e-3))\n",
        "        # return global_mean_pool(node_embeddings, batch=None)\n",
        "        return node_embeddings.mean(dim=1)\n",
        "\n",
        "test_readout(MeanReadout, expected_mean_readout)\n",
        "# expected_mean_readout = torch.tensor(\n",
        "#     [[-0.0035, 0.0505, -0.2221, 0.1404, 0.1922, -0.3736, -0.0672, 0.0752,\n",
        "#       -0.0613, 0.0439, -0.1307, -0.0752, -0.0310, 0.0081, -0.0553, -0.1734],\n",
        "#      [-0.0054, -0.0144, -0.3113, 0.1665, 0.0738, -0.3303, 0.0420, 0.0668,\n",
        "#       0.0494, 0.2648, -0.0478, 0.0550, -0.1923, -0.0157, 0.0508, 0.0148],\n",
        "#      [-0.1912, 0.0309, -0.1512, 0.1283, 0.1120, -0.4540, -0.0644, 0.1378,\n",
        "#       -0.0194, 0.0103, -0.1713, 0.0175, -0.0604, -0.0193, -0.0208, -0.0822]]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.738451Z",
          "start_time": "2023-12-11T15:15:49.667644Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13bd85d993f87d63",
        "outputId": "42089a0d-5c70-4064-eac9-3d6817b4e865"
      },
      "id": "13bd85d993f87d63"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2. Implement attention readout (2 points).\n",
        "Implement the attention readout given by formula $x = \\sum_i^n \\frac{\\exp(score_i))}{\\sum_j^n \\exp(score_j)}x_i$, where $score_i=score\\_mlp(x_i)$:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "db68abdbc2736d7a"
      },
      "id": "db68abdbc2736d7a"
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "class AttentionReadout(ReadoutBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__(hidden_size)\n",
        "        self.score_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        node_embeddings, _ = to_dense_embeddings(node_embeddings, graph)\n",
        "        result = torch.sum(((torch.exp(self.score_mlp(node_embeddings),)) / (torch.sum(torch.exp(self.score_mlp(node_embeddings)), dim=1, keepdim=True))) * node_embeddings, dim=1)\n",
        "\n",
        "        return result\n",
        "\n",
        "test_readout(AttentionReadout, expected_attention_readout)\n",
        "# expected_attention_readout = torch.Tensor(\n",
        "#     [[-0.0083, 0.0499, -0.2197, 0.1380, 0.1921, -0.3753, -0.0669, 0.0771,\n",
        "#       -0.0592, 0.0411, -0.1317, -0.0769, -0.0299, 0.0074, -0.0568, -0.1741],\n",
        "#      [-0.0068, -0.0131, -0.3102, 0.1656, 0.0736, -0.3312, 0.0410, 0.0670,\n",
        "#       0.0485, 0.2635, -0.0479, 0.0544, -0.1933, -0.0162, 0.0508, 0.0150],\n",
        "#      [-0.1911, 0.0308, -0.1514, 0.1271, 0.1100, -0.4542, -0.0658, 0.1376,\n",
        "#       -0.0215, 0.0099, -0.1723, 0.0164, -0.0618, -0.0209, -0.0217, -0.0817]],\n",
        "# )\n",
        "\n",
        "#my:\n",
        "# tensor([[-0.0083,  0.0499, -0.2197,  0.1380,  0.1921, -0.3753, -0.0669,  0.0771,\n",
        "#          -0.0592,  0.0411, -0.1317, -0.0769, -0.0299,  0.0074, -0.0568, -0.1741],\n",
        "#         [-0.0025, -0.0049, -0.1165,  0.0622,  0.0276, -0.1244,  0.0154,  0.0252,\n",
        "#           0.0182,  0.0990, -0.0180,  0.0204, -0.0726, -0.0061,  0.0191,  0.0056],\n",
        "#         [-0.0728,  0.0117, -0.0576,  0.0484,  0.0419, -0.1729, -0.0250,  0.0524,\n",
        "#          -0.0082,  0.0038, -0.0656,  0.0062, -0.0235, -0.0080, -0.0083, -0.0311]],\n",
        "#        grad_fn=<SumBackward1>)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.779192Z",
          "start_time": "2023-12-11T15:15:49.674122Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c1f5bcdbc90881",
        "outputId": "a4415f56-de92-421d-891b-5af759e861fa"
      },
      "id": "6c1f5bcdbc90881"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Message Passing Neural Networks (MPNNs)\n",
        "Message Passing is given by formula:\n",
        "$$\n",
        "x'_i=\\rho(x_i, \\square_{j\\in N(i)} \\psi(x_j, x_i, e_{ji})),\n",
        "$$\n",
        "where $\\psi$ is learnable message function, $\\rho$ is learnable update, and $\\square$ is aggregation function."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ac465a3b9279474b"
      },
      "id": "ac465a3b9279474b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple MPNN\n",
        "For instance, we can define a very simple MPNN layer by the following formula:\n",
        "$$\n",
        "x'_i=W_1x_i + W_2\\sum_{j\\in N(i)} W_3x_j,\n",
        "$$\n",
        "where W_i are linear layers with implicit bias term (we will make the bias implicit in every formula in that notebook). Let us implement this simple MPNN:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "307c236e3cb84e76"
      },
      "id": "307c236e3cb84e76"
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "outputs": [],
      "source": [
        "class SimpleMPNNLayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_3 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        # graph is bi-directed, so we can freely swap the \"start\" and \"end\" meanings\n",
        "        start_nodes, end_nodes = graph.edges(order='srcdst') # using this `order` value sorts the `start_nodes`\n",
        "        messages = self.linear_3(node_embeddings[end_nodes]) # W_3x_j\n",
        "        message_dense, _ = to_dense_batch(messages, start_nodes.long(), fill_value=0.0) # to make the life easier, we convert the node embeddings to dense representation\n",
        "        aggregated_message = message_dense.sum(dim=1) # \\sum_{j\\in N(i)} W_3x_j\n",
        "        aggregated_message = self.linear_2(aggregated_message) # W_2\\sum_{j\\in N(i)} W_3x_j\n",
        "        node_embeddings = self.linear_1(node_embeddings) + aggregated_message # W_1x_i + W_2\\sum_{j\\in N(i)} W_3x_j\n",
        "        return node_embeddings"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.779483Z",
          "start_time": "2023-12-11T15:15:49.679591Z"
        },
        "id": "f11f284c299831ed"
      },
      "id": "f11f284c299831ed"
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "outputs": [],
      "source": [
        "def test_mpnn_layer(mpnn_layer_cls: Type[MPNNLayerBase], expected_output: torch.Tensor):\n",
        "    torch.manual_seed(0)\n",
        "    graph = dgl.batch([dataset[0][1], dataset[1][1]])\n",
        "    linear_nodes = nn.Linear(node_featurizer.feat_size(), 4)\n",
        "    linear_edges = nn.Linear(edge_featurizer.feat_size(), 4)\n",
        "    node_embeddings = linear_nodes(graph.ndata['h'])\n",
        "    edge_embeddings = linear_edges(graph.edata['e'])\n",
        "    layer = mpnn_layer_cls(hidden_size=4)\n",
        "    result = layer(node_embeddings, edge_embeddings, graph)\n",
        "    assert torch.allclose(result, expected_output, atol=1e-3)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.779529Z",
          "start_time": "2023-12-11T15:15:49.683224Z"
        },
        "id": "8767bffa62008f67"
      },
      "id": "8767bffa62008f67"
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "outputs": [],
      "source": [
        "test_mpnn_layer(SimpleMPNNLayer, expected_simple_mpnn_output)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.779871Z",
          "start_time": "2023-12-11T15:15:49.685486Z"
        },
        "id": "461980b684728501"
      },
      "id": "461980b684728501"
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.function as fn"
      ],
      "metadata": {
        "id": "1w_ODzfEt7dk"
      },
      "id": "1w_ODzfEt7dk",
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3. Implement GraphSAGE layer (2 points).\n",
        "Implement a GraphSAGE given by the following formula:\n",
        "$$\n",
        "x'_i=W_1x_i + W_2\\frac{1}{deg(i)}\\sum_{j\\in N(i)} x_j,\n",
        "$$\n",
        "where $deg(i) = #N(i)$ is the number of neighbors of node $i$."
      ],
      "metadata": {
        "collapsed": false,
        "id": "d0dbbc2f2efa8ca2"
      },
      "id": "d0dbbc2f2efa8ca2"
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "outputs": [],
      "source": [
        "class SAGELayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        with graph.local_scope():\n",
        "            # Message Passing: Aggregate messages from neighbors\n",
        "            graph.ndata['h'] = node_embeddings\n",
        "            graph.update_all(message_func=self.message_func, reduce_func=self.reduce_func)\n",
        "\n",
        "            # Calculate the degree of each node\n",
        "            deg = graph.in_degrees().float().clamp(min=1)\n",
        "\n",
        "            # Normalize aggregated messages by the degree of each node\n",
        "            graph.ndata['h_neigh'] = graph.ndata['h_neigh'] / deg.unsqueeze(-1)\n",
        "\n",
        "            # Perform linear transformations\n",
        "            h_linear_1 = self.linear_1(node_embeddings)\n",
        "            h_neigh_linear_2 = self.linear_2(graph.ndata['h_neigh'])\n",
        "\n",
        "            # Sum the two sets of transformed embeddings\n",
        "            h_combined = h_linear_1 + h_neigh_linear_2\n",
        "\n",
        "            return h_combined\n",
        "    def message_func(self, edges):\n",
        "        return {'m': edges.src['h']}\n",
        "\n",
        "    def reduce_func(self, nodes):\n",
        "        return {'h_neigh': torch.sum(nodes.mailbox['m'], dim=1)}\n",
        "\n",
        "test_mpnn_layer(SAGELayer, expected_sage_layer_output)\n",
        "\n",
        "    # [[-5.0965e-01, -4.5482e-01, -8.1451e-01, 5.4286e-03],\n",
        "    #  [-5.6737e-01, -5.9137e-01, -7.9304e-01, 7.5955e-02],\n",
        "    #  [-4.6768e-01, -5.0346e-01, -7.2765e-01, 5.0357e-02],\n",
        "    #  [-6.4185e-01, -5.0983e-01, -8.6305e-01, 1.3008e-02],\n",
        "    #  [-5.0465e-01, -3.5816e-01, -8.7864e-01, -3.1902e-02],\n",
        "    #  [-5.6591e-01, -4.2403e-01, -8.7506e-01, 2.9357e-02],\n",
        "    #  [-6.4185e-01, -5.0983e-01, -8.6305e-01, 1.3008e-02],\n",
        "    #  [-5.7196e-01, -3.5674e-01, -9.4769e-01, -4.9931e-03],\n",
        "    #  [-6.4185e-01, -5.0983e-01, -8.6305e-01, 1.3008e-02],\n",
        "    #  [-5.2655e-01, -5.1094e-01, -8.3806e-01, -1.8521e-02],\n",
        "    #  [-6.4185e-01, -5.0983e-01, -8.6305e-01, 1.3008e-02],\n",
        "    #  [-5.7628e-01, -5.5394e-01, -8.7300e-01, -7.6976e-03],\n",
        "    #  [-4.6768e-01, -5.0346e-01, -7.2765e-01, 5.0357e-02],\n",
        "    #  [-5.4808e-01, -5.3204e-01, -7.8906e-01, 4.2878e-02],\n",
        "    #  [-5.3417e-01, -3.5912e-01, -9.5030e-01, 2.3648e-05],\n",
        "    #  [-6.2538e-01, -2.9249e-01, -1.1233e+00, 1.0970e-01],\n",
        "    #  [-6.5214e-01, -3.8342e-01, -1.0136e+00, -1.6424e-02],\n",
        "    #  [-6.5214e-01, -3.8342e-01, -1.0136e+00, -1.6424e-02]],"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.779946Z",
          "start_time": "2023-12-11T15:15:49.691201Z"
        },
        "id": "82528a8dacf24cd3"
      },
      "id": "82528a8dacf24cd3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4. Implement GIN layer (2 points).\n",
        "Implement a GIN layer given by the following formula:\n",
        "$$\n",
        "x'_i=mlp((1 + \\epsilon)x_i + \\sum_{j\\in N(i)} x_j).\n",
        "$$"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ea8735b272ecad46"
      },
      "id": "ea8735b272ecad46"
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "outputs": [],
      "source": [
        "class GINLayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, eps: float = 0.0):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.eps = eps\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "        )\n",
        "    def message_func(self, edges):\n",
        "      return {'m': edges.src['h']}\n",
        "\n",
        "    def reduce_func(self, nodes):\n",
        "      return {'h_neigh': torch.sum(nodes.mailbox['m'], dim=1)}\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "\n",
        "        graph.ndata['h'] = node_embeddings\n",
        "        graph.update_all(message_func=self.message_func, reduce_func=self.reduce_func)\n",
        "        # Calculate the degree of each node\n",
        "        # Normalize aggregated messages by the degree of each node\n",
        "        graph.ndata['h_neigh'] = graph.ndata['h_neigh']\n",
        "\n",
        "\n",
        "        result = self.mlp((1+self.eps) * node_embeddings + graph.ndata['h_neigh'])\n",
        "\n",
        "        return result\n",
        "    # [[-0.4516, -0.3673, -0.5313, 0.3170],\n",
        "    #  [-0.4524, -0.3760, -0.5243, 0.3249],\n",
        "    #  [-0.4570, -0.3747, -0.5313, 0.3221],\n",
        "    #  [-0.4763, -0.4030, -0.5390, 0.3335],\n",
        "    #  [-0.4481, -0.3855, -0.5187, 0.3295],\n",
        "    #  [-0.4545, -0.3838, -0.5245, 0.3276],\n",
        "    #  [-0.4763, -0.4030, -0.5390, 0.3335],\n",
        "    #  [-0.4390, -0.4001, -0.4973, 0.3446],\n",
        "    #  [-0.4763, -0.4030, -0.5390, 0.3335],\n",
        "    #  [-0.4683, -0.3882, -0.5400, 0.3248],\n",
        "    #  [-0.4763, -0.4030, -0.5390, 0.3335],\n",
        "    #  [-0.4682, -0.3921, -0.5374, 0.3277],\n",
        "    #  [-0.4570, -0.3747, -0.5313, 0.3221],\n",
        "    #  [-0.4225, -0.3671, -0.4928, 0.3295],\n",
        "    #  [-0.3760, -0.3700, -0.4407, 0.3489],\n",
        "    #  [-0.2646, -0.3342, -0.3357, 0.3683],\n",
        "    #  [-0.3859, -0.3950, -0.4392, 0.3624],\n",
        "    #  [-0.3859, -0.3950, -0.4392, 0.3624]],\n",
        "test_mpnn_layer(GINLayer, expected_gin_layer_output)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.779991Z",
          "start_time": "2023-12-11T15:15:49.697036Z"
        },
        "id": "e422bea1856fc29"
      },
      "id": "e422bea1856fc29"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5. Implement GINE layer (2 points).\n",
        "Implement a GINE layer given by the following formula:\n",
        "$$\n",
        "x'_i=mlp((1 + \\epsilon)x_i + \\sum_{j\\in N(i)} ReLU(x_j + e_{ji})).\n",
        "$$"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9fe4ec2134b539da"
      },
      "id": "9fe4ec2134b539da"
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-332-8bbddc2c8f5f>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgine_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtest_mpnn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGINELayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_gine_layer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-327-9d592ae8525c>\u001b[0m in \u001b[0;36mtest_mpnn_layer\u001b[0;34m(mpnn_layer_cls, expected_output)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpnn_layer_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class GINELayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, eps: float = 0.0):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.eps = eps\n",
        "        self.relu = nn.ReLU()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        start_nodes, end_nodes, edge_ids = graph.edges(order='srcdst', form='all')\n",
        "\n",
        "        end_nodes = end_nodes.long()\n",
        "        start_nodes = start_nodes.long()\n",
        "        # Compute neighbors for edge embeddings\n",
        "\n",
        "        neighbor_edge_embeddings = edge_embeddings[edge_ids]\n",
        "\n",
        "        # Compute the sum of neighbor edge embeddings and node embeddings\n",
        "        sum_neighbor_embeddings = torch.zeros_like(node_embeddings)\n",
        "        sum_neighbor_embeddings.scatter_add_(0, end_nodes.unsqueeze(1).expand_as(neighbor_edge_embeddings),\n",
        "                                            self.relu(node_embeddings[end_nodes] + neighbor_edge_embeddings[end_nodes]))\n",
        "        # sum_neighbor_embeddings.scatter_add_(0, start_nodes.unsqueeze(1).expand_as(neighbor_edge_embeddings),\n",
        "                                            # self.relu(node_embeddings[start_nodes] + neighbor_edge_embeddings[start_nodes]))\n",
        "        gine_update = self.mlp((1 + self.eps) * node_embeddings + sum_neighbor_embeddings)\n",
        "\n",
        "        return gine_update\n",
        "\n",
        "test_mpnn_layer(GINELayer, expected_gine_layer_output)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.780022Z",
          "start_time": "2023-12-11T15:15:49.702353Z"
        },
        "id": "635e6bcb4e40fdd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "3a6b764d-1c61-4ea9-f849-cdc5d371e118"
      },
      "id": "635e6bcb4e40fdd2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6b220afd7f1d78b8"
      },
      "id": "6b220afd7f1d78b8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logger\n",
        "We are going to use [wandb](https://wandb.ai/site) for logging. It's a very convenient tool for logging and visualizing the training process. It's free for academic use, so you can create an account and use it for your projects. If you don't want to use wandb, you can use any other online logger (like [comet.ml](https://www.comet.ml/site/)), but you need to implement the appropriate LoggerBase subclass on your own. To setup and use wandb, you need to do the following:\n",
        "1. [Setup the wandb](https://docs.wandb.ai/quickstart) (or any other online logger).\n",
        "2. Give your supervisor access to your project (ask him/her about the username.\n",
        "3. Use the logger for all your trainings and provide the links to the final runs."
      ],
      "metadata": {
        "collapsed": false,
        "id": "2f465e5d378487e7"
      },
      "id": "2f465e5d378487e7"
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "outputs": [],
      "source": [
        "class WandbLogger(LoggerBase):\n",
        "    def __init__(\n",
        "            self, logdir: str | Path, project_name: str, experiment_name: str, **kwargs: Dict[str, Any]\n",
        "    ):\n",
        "        super().__init__(logdir)\n",
        "        import wandb\n",
        "        self.project_name = project_name\n",
        "        self.experiment_name = experiment_name\n",
        "        self.kwargs = kwargs\n",
        "        self.run = wandb.init(\n",
        "            dir=self.logdir,\n",
        "            project=self.project_name,\n",
        "            name=self.experiment_name,\n",
        "            **self.kwargs,\n",
        "        )\n",
        "\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        metrics = {f\"{prefix}/{k}\": v for k, v in metrics.items()}\n",
        "        self.run.log(metrics)\n",
        "\n",
        "    def close(self):\n",
        "        self.run.finish()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.780089Z",
          "start_time": "2023-12-11T15:15:49.708043Z"
        },
        "id": "1462ef331426d529"
      },
      "id": "1462ef331426d529"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 6. Train GraphSAGE (2 points).\n",
        "1. Tune hyperparameters of a GNN with `SAGELayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: [your link]"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1db91eaab1a90175"
      },
      "id": "1db91eaab1a90175"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "### Example code for training. You can modify it for easier grid-searching."
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.780133Z",
          "start_time": "2023-12-11T15:15:49.710445Z"
        },
        "id": "e3e9e0cf69701d46"
      },
      "id": "e3e9e0cf69701d46"
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def get_time_stamp() -> str:\n",
        "    return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-11T15:15:49.780168Z",
          "start_time": "2023-12-11T15:15:49.713308Z"
        },
        "id": "2980b66ad10a9824"
      },
      "id": "2980b66ad10a9824"
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:ig5xl11q) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cbaa81e44a742269694a8703d7893db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/loss</td><td>▄▂▃▃▁▄▂▁▂▂▁▂▃▁▂▂▃▂▁▁▄▁▂▂▂▄▂▂▂▂▂▁▂█▁▂▂▂▂▃</td></tr><tr><td>train/mae</td><td>▄▂▃▃▂▃▃▂▂▂▂▂▃▂▂▂▃▂▂▂▃▂▂▂▂▃▂▃▂▃▂▁▂█▂▂▂▃▂▃</td></tr><tr><td>train/mse</td><td>▄▂▃▃▁▄▂▁▂▂▁▂▃▁▂▂▃▂▁▁▄▁▂▂▂▄▂▂▂▂▂▁▂█▁▂▂▂▂▃</td></tr><tr><td>train/pcc</td><td>▁▆▂▁▆▃▄▅▆▃▆▃▆ ▅▅▅▅▆▄▇▆▇▆▆▆▄▅▅▆▅█▇ ▆▇▅▆▇▆</td></tr><tr><td>valid/loss</td><td>█▃▃▃▃▃▃▃▃▃▂▂▄▂▁▂▁▂▂▂▂▂▁▁▁▃▃▂▂▂▂▁▂▂▁▁▁▁▁▃</td></tr><tr><td>valid/mae</td><td>█▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▁▂▂▁▂▂▁▁▂▃▃▂▂▂▂▂▂▂▂▁▁▁▁▂</td></tr><tr><td>valid/mse</td><td>█▃▃▃▃▃▃▃▃▃▂▂▄▂▁▂▁▂▂▂▂▂▁▁▁▃▃▂▂▂▂▁▂▂▁▁▁▁▁▃</td></tr><tr><td>valid/pcc</td><td>▁▁▂▂▂▂▃▃▃▅▄▅▇▇▆█▇▆██▇▇█▇▇▆▅▅▆▆▆▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/loss</td><td>7.77638</td></tr><tr><td>train/mae</td><td>2.09908</td></tr><tr><td>train/mse</td><td>7.77638</td></tr><tr><td>train/pcc</td><td>0.80455</td></tr><tr><td>valid/loss</td><td>30.88809</td></tr><tr><td>valid/mae</td><td>3.6117</td></tr><tr><td>valid/mse</td><td>30.88809</td></tr><tr><td>valid/pcc</td><td>0.72476</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sage_2023-12-29_20-23-51</strong> at: <a href='https://wandb.ai/mariia-saltykova-work/mldd23/runs/ig5xl11q' target=\"_blank\">https://wandb.ai/mariia-saltykova-work/mldd23/runs/ig5xl11q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>runs/mpnn/wandb/run-20231229_202503-ig5xl11q/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:ig5xl11q). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>runs/mpnn/wandb/run-20231229_203028-ociinw2e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mariia-saltykova-work/mldd23/runs/ociinw2e' target=\"_blank\">sage_2023-12-29_20-30-28</a></strong> to <a href='https://wandb.ai/mariia-saltykova-work/mldd23' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mariia-saltykova-work/mldd23' target=\"_blank\">https://wandb.ai/mariia-saltykova-work/mldd23</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mariia-saltykova-work/mldd23/runs/ociinw2e' target=\"_blank\">https://wandb.ai/mariia-saltykova-work/mldd23/runs/ociinw2e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e0e5bc061554842b8a89e56ae8d7baf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: The variance of predictions or target is close to zero. This can cause instability in Pearson correlationcoefficient, leading to wrong results. Consider re-scaling the input if possible or computing using alarger dtype (currently using torch.float32).\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.11252950948675353, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e0c2fe0796d4b6d94df9ac3851326aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mae</td><td>▁</td></tr><tr><td>test/mse</td><td>▁</td></tr><tr><td>test/pcc</td><td>▁</td></tr><tr><td>train/loss</td><td>█▂▄▂▂▃▅▂▃▃▂▃▂▂▂▂▃▃▂▇▂▂▃▃▇█▁▂▂▂▂▂▂▂▂▃▃▂▁▂</td></tr><tr><td>train/mae</td><td>▆▂▃▂▂▃▆▂▄▃▂▃▂▃▂▂▃▃▂▅▂▂▃▃▃█▁▂▂▂▂▂▂▂▂▃▃▂▁▂</td></tr><tr><td>train/mse</td><td>█▂▄▂▂▃▅▂▃▃▂▃▂▂▂▂▃▃▂▇▂▂▃▃▇█▁▂▂▂▂▂▂▂▂▃▃▂▁▂</td></tr><tr><td>train/pcc</td><td>▁▆▂▂▆▅ ▄▆▆▆▅▇▅▆▇▅▄▅█▇▇▆▆▆ ▆▇▇▆██▇▇▇▆▆▇▇█</td></tr><tr><td>valid/loss</td><td>█▃▃▄▃▃▃▂▃▃▂▃▂▁▁▃▂▃▂▂▂▁▁▁▃▃▂▂▂▂▁▂▂▁▁▁▁▂▃▁</td></tr><tr><td>valid/mae</td><td>█▄▄▄▃▃▃▃▃▃▃▂▂▂▁▂▂▂▂▂▂▁▁▂▃▃▂▂▂▂▂▂▂▁▁▁▁▁▂▂</td></tr><tr><td>valid/mse</td><td>█▃▃▄▃▃▃▂▃▃▂▃▂▁▁▃▂▃▂▂▂▁▁▁▃▃▂▂▂▂▁▂▂▁▁▁▁▂▃▁</td></tr><tr><td>valid/pcc</td><td>▁▁▂▂▂▂▃▃▃▄▅▆▆▆▇▇▆▇█▇▇█▇▇▆▅▅▆▆▆▇▇▇▇████▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>13.44511</td></tr><tr><td>test/mae</td><td>2.68803</td></tr><tr><td>test/mse</td><td>11.13722</td></tr><tr><td>test/pcc</td><td>0.52504</td></tr><tr><td>train/loss</td><td>0.12497</td></tr><tr><td>train/mae</td><td>0.35352</td></tr><tr><td>train/mse</td><td>0.12497</td></tr><tr><td>train/pcc</td><td>nan</td></tr><tr><td>valid/loss</td><td>25.75956</td></tr><tr><td>valid/mae</td><td>3.672</td></tr><tr><td>valid/mse</td><td>25.75956</td></tr><tr><td>valid/pcc</td><td>0.63133</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sage_2023-12-29_20-30-28</strong> at: <a href='https://wandb.ai/mariia-saltykova-work/mldd23/runs/ociinw2e' target=\"_blank\">https://wandb.ai/mariia-saltykova-work/mldd23/runs/ociinw2e</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>runs/mpnn/wandb/run-20231229_203028-ociinw2e/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation metrics: {'loss': 25.759555339813232, 'mae': 3.6720032691955566, 'mse': 25.75955581665039, 'pcc': 0.6313266754150391}\n",
            "Test metrics: {'loss': 13.445105075836182, 'mae': 2.6880316734313965, 'mse': 11.137218475341797, 'pcc': 0.5250446796417236}\n"
          ]
        }
      ],
      "source": [
        "from torchmetrics import MeanAbsoluteError as MAE\n",
        "from torchmetrics import MeanSquaredError as MSE\n",
        "from torchmetrics import PearsonCorrCoef as PCC\n",
        "\n",
        "metrics = {\n",
        "    \"mae\": MAE(),\n",
        "    \"mse\": MSE(),\n",
        "    \"pcc\": PCC(),\n",
        "}\n",
        "\n",
        "model = GNN(\n",
        "    node_features_size=node_featurizer.feat_size(),\n",
        "    edge_features_size=edge_featurizer.feat_size(),\n",
        "    hidden_size=256,\n",
        "    output_size=1,\n",
        "    mpnn_layer_cls=SAGELayer,\n",
        "    mpnn_n_layers=6,\n",
        "    readout_cls=MeanReadout,\n",
        "    mpnn_layer_kwargs={}\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    run_dir=\"experiments\",\n",
        "    train_dataset=train,\n",
        "    valid_dataset=valid,\n",
        "    train_metrics=metrics,\n",
        "    valid_metrics=metrics,\n",
        "    train_batch_size=32,\n",
        "    model=model,\n",
        "    logger=WandbLogger(\n",
        "        logdir=\"runs/mpnn\",\n",
        "        project_name=\"mldd23\",\n",
        "        experiment_name=f\"sage_{get_time_stamp()}\",\n",
        "    ),\n",
        "    optimizer_kwargs={\"lr\": 1e-4},\n",
        "    n_epochs=50,\n",
        "    device=\"cpu\",\n",
        "    valid_every_n_epochs=1,\n",
        ")\n",
        "\n",
        "valid_metrics = trainer.train()\n",
        "test_metrics = trainer.test(test)\n",
        "trainer.close()\n",
        "print(f\"Validation metrics: {valid_metrics}\")\n",
        "print(f\"Test metrics: {test_metrics}\")"
      ],
      "metadata": {
        "id": "18cd039ad8f03ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989,
          "referenced_widgets": [
            "7cbaa81e44a742269694a8703d7893db",
            "91583e5186634d0290fb64f6f545f230",
            "2039d2c1f0f8478cb0ad1c3da73db0fe",
            "65a9197a320b49948f263126848b6373",
            "6e3e5d314e9e49cbb7cb7428102367c8",
            "e90e5ab709464439a226da0b701ca565",
            "2edcc801ad064a739b9d644f06f36235",
            "3bf4cdd16a10448da66344d3af7510fa",
            "4e0e5bc061554842b8a89e56ae8d7baf",
            "302bd1bdb39f46a6a034dfa263e92e3f",
            "c00de4c0c66e456ea02f8cc6296e3274",
            "c879d51be2014bf29be1839cdcf4502a",
            "c4d4921d82a543959ad30d4e080cec57",
            "43c3c9c3ec464edbb31b2d57c43d31e5",
            "5cd65383b0484404ac2c008426aa21d0",
            "cf4599f1fbf54d9da7fe2b5397a1e7db",
            "1d91129ddbec43b19ef3ae1b0d28487d",
            "83c0d953bc1d4d9d830da7048c540d8d",
            "63fe4b4dc00a4dc38fb4e92b8b26327a",
            "9e0c2fe0796d4b6d94df9ac3851326aa",
            "ec079f67902b4aeaa766727e29abb372",
            "242f4bc8faab4d7aa45dd92fba963c6f",
            "698b5a950e5a47e095f22ef3270ce183",
            "b96937ecedff4c3a988c47bfee5f4240",
            "2f2b3469caba453aa7c0c3bc7765ac0c",
            "0085e5fa07a9429db9f3672b00c8b231",
            "6858dc29218141288fded8c04bcfebde"
          ]
        },
        "outputId": "5c6a2633-1ec6-486a-a5d5-45306e45557d"
      },
      "id": "18cd039ad8f03ca6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 7. Train GIN (2 points).\n",
        "1. Tune hyperparameters of a GNN with `GINLayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: [your link]"
      ],
      "metadata": {
        "collapsed": false,
        "id": "c0acbbdb6f55d814"
      },
      "id": "c0acbbdb6f55d814"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 8. Train GINE (2 points).\n",
        "1. Tune hyperparameters of a GNN with `GINELayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: [your link]"
      ],
      "metadata": {
        "collapsed": false,
        "id": "100ee2cd44877b2c"
      },
      "id": "100ee2cd44877b2c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code optimization\n",
        "Some pieces of code were written suboptimally. Your task is to slightly optimize them."
      ],
      "metadata": {
        "collapsed": false,
        "id": "802615e3afaddf44"
      },
      "id": "802615e3afaddf44"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 9. Optimize SumReadout (1 point).\n",
        "`SumReadout` was written using `to_dense_embeddings` function which does some unecessary memory allocations and computations. Your task is to rewrite the method using code from a bare torch library. Hint: `torch.index_add`."
      ],
      "metadata": {
        "collapsed": false,
        "id": "17c64785b23a2b1d"
      },
      "id": "17c64785b23a2b1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class OptimizedSumReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "test_readout(OptimizedSumReadout, expected_sum_readout)"
      ],
      "metadata": {
        "is_executing": true,
        "id": "292cb0197e977862"
      },
      "id": "292cb0197e977862"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 10. Optimize MeanReadout (1 point).\n",
        "Your task is to rewrite the method using code from a bare torch library."
      ],
      "metadata": {
        "collapsed": false,
        "id": "d4be6a2ed6011b64"
      },
      "id": "d4be6a2ed6011b64"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class OptimizedMeanReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "test_readout(OptimizedMeanReadout, expected_mean_readout)"
      ],
      "metadata": {
        "is_executing": true,
        "id": "9baf5944d7ad42c2"
      },
      "id": "9baf5944d7ad42c2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 11. Optimize SimpleMPNNLayer (1 point).\n",
        "We can make our implementations of `SimpleMPNNLayer` layer (and basically any other MPNN layer) slightly faster by:\n",
        "- reducing the costs of the message embedding (in the case of `SimpleMPNNLayer`, it's application of `self.linear_3`) from $O(m)$ to $O(n)$, where $m$ is the number of edges in the graph and $n$ is the number of nodes.\n",
        "- removing quite expensive `to_dense_batch` call.\n",
        "\n",
        "Your task is to apply the above optimizations."
      ],
      "metadata": {
        "collapsed": false,
        "id": "6b0f8cab6725a285"
      },
      "id": "6b0f8cab6725a285"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class OptimizedSimpleMPNNLayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_3 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "test_mpnn_layer(OptimizedSimpleMPNNLayer, expected_simple_mpnn_output)"
      ],
      "metadata": {
        "is_executing": true,
        "id": "862db51e45f8abf"
      },
      "id": "862db51e45f8abf"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7cbaa81e44a742269694a8703d7893db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91583e5186634d0290fb64f6f545f230",
              "IPY_MODEL_2039d2c1f0f8478cb0ad1c3da73db0fe"
            ],
            "layout": "IPY_MODEL_65a9197a320b49948f263126848b6373"
          }
        },
        "91583e5186634d0290fb64f6f545f230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e3e5d314e9e49cbb7cb7428102367c8",
            "placeholder": "​",
            "style": "IPY_MODEL_e90e5ab709464439a226da0b701ca565",
            "value": "11.938 MB of 11.938 MB uploaded\r"
          }
        },
        "2039d2c1f0f8478cb0ad1c3da73db0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2edcc801ad064a739b9d644f06f36235",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bf4cdd16a10448da66344d3af7510fa",
            "value": 1
          }
        },
        "65a9197a320b49948f263126848b6373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3e5d314e9e49cbb7cb7428102367c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e90e5ab709464439a226da0b701ca565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2edcc801ad064a739b9d644f06f36235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bf4cdd16a10448da66344d3af7510fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e0e5bc061554842b8a89e56ae8d7baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_302bd1bdb39f46a6a034dfa263e92e3f",
              "IPY_MODEL_c00de4c0c66e456ea02f8cc6296e3274",
              "IPY_MODEL_c879d51be2014bf29be1839cdcf4502a"
            ],
            "layout": "IPY_MODEL_c4d4921d82a543959ad30d4e080cec57"
          }
        },
        "302bd1bdb39f46a6a034dfa263e92e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43c3c9c3ec464edbb31b2d57c43d31e5",
            "placeholder": "​",
            "style": "IPY_MODEL_5cd65383b0484404ac2c008426aa21d0",
            "value": "100%"
          }
        },
        "c00de4c0c66e456ea02f8cc6296e3274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf4599f1fbf54d9da7fe2b5397a1e7db",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d91129ddbec43b19ef3ae1b0d28487d",
            "value": 50
          }
        },
        "c879d51be2014bf29be1839cdcf4502a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83c0d953bc1d4d9d830da7048c540d8d",
            "placeholder": "​",
            "style": "IPY_MODEL_63fe4b4dc00a4dc38fb4e92b8b26327a",
            "value": " 50/50 [02:07&lt;00:00,  2.55s/it]"
          }
        },
        "c4d4921d82a543959ad30d4e080cec57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c3c9c3ec464edbb31b2d57c43d31e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd65383b0484404ac2c008426aa21d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf4599f1fbf54d9da7fe2b5397a1e7db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d91129ddbec43b19ef3ae1b0d28487d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83c0d953bc1d4d9d830da7048c540d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63fe4b4dc00a4dc38fb4e92b8b26327a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e0c2fe0796d4b6d94df9ac3851326aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec079f67902b4aeaa766727e29abb372",
              "IPY_MODEL_242f4bc8faab4d7aa45dd92fba963c6f"
            ],
            "layout": "IPY_MODEL_698b5a950e5a47e095f22ef3270ce183"
          }
        },
        "ec079f67902b4aeaa766727e29abb372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b96937ecedff4c3a988c47bfee5f4240",
            "placeholder": "​",
            "style": "IPY_MODEL_2f2b3469caba453aa7c0c3bc7765ac0c",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "242f4bc8faab4d7aa45dd92fba963c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0085e5fa07a9429db9f3672b00c8b231",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6858dc29218141288fded8c04bcfebde",
            "value": 1
          }
        },
        "698b5a950e5a47e095f22ef3270ce183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b96937ecedff4c3a988c47bfee5f4240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f2b3469caba453aa7c0c3bc7765ac0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0085e5fa07a9429db9f3672b00c8b231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6858dc29218141288fded8c04bcfebde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}